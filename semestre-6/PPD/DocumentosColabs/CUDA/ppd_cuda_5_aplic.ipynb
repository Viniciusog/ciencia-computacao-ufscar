{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rF76EjM3ZQ7r"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF76EjM3ZQ7r"
      },
      "source": [
        "# PPD: Programação com CUDA\n",
        "\n",
        "Hélio - DC/UFSCar - 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estudo de caso: soma de matrizes\n",
        "\n",
        "Neste estudo de casos, investigamos a realização de uma soma de 2 matrizes em GPU.\n",
        "\n",
        "É claro que a ideia é realizar a soma de cada par de elementos em paralelo, criando um número de *threads* igual ao número de elementos a somar, o que corresponde à multiplicação do número de linhas pelo número de colunas.\n",
        "\n",
        "Há outras questões a considerar, contudo. A primeira é como será o armazenamento das matrizes na memória da GPU.\n",
        "\n",
        "Supondo que os dados seriam lidos de um arquivo, ou gerados de alguma outra forma em CPU, e não na própria GPU, é preciso alocar espaço na memória do dispositivo (*device*/GPU) e copiar os dados da RAM para esse espaço alocado na GPU.\n",
        "\n",
        "Como organizar os dados das matrizes na memória da GPU? Comumente, alocar o espaço como uma sequência de linhas parece mais fácil.\n",
        "\n",
        "Outra questão a considerar é como organizar as *threads* em blocos e os blocos em grade, e como usar esses identificadores para determinar a soma de quais elementos será calculada por cada *thread*.\n",
        "\n",
        "Vejamos 2 exemplos, que exploram **blocos 2D e grade 2D** e **blocos 1D e grade 1D**.\n"
      ],
      "metadata": {
        "id": "HyiS14sf-lEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bloco 2D e grade 2D\n",
        "\n",
        "Nesta estratégia de particionamento do cálculos dos elementos, tanto o bloco de *threads* quanto a grade de blocos são organizados em estruturas 2D, utilizando os parâmetros .x e .y da estrutura dim3 (.z é mantido em 1).\n",
        "\n",
        "Como se vê, a estratégia de ajustes dos índices ***i*** e ***j*** das *threads* é a mesma, que considera o identificador do bloco vezes o tamanho do bloco, em cada uma das dimensões (.x e .y).\n",
        "\n",
        "Ao final, os valores i e j acabam sendo linearizados para o acesso à matriz, da forma tradicional (i * num_col + j).\n"
      ],
      "metadata": {
        "id": "7yeDWqVPbTkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 2dx2d.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define DIM 10240\n",
        "\n",
        "\n",
        "__global__ void somaMatrizes(float *A, float *B, float *C, int dim )\n",
        "{\n",
        "\tunsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  unsigned idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "\tif (idx < dim && idy < dim)\n",
        "\t\tC[idx * dim + idy] = A[idx * dim + idy] + B[idx * dim + idy];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  float *A, *B, *C;          // ponteiros para matrizes na RAM\n",
        "  float *d_A, *d_B, *d_C;    // ponteiros para matrizes na GPU\n",
        "\n",
        "  int n_elem = DIM;\n",
        "  size_t tam_mat = n_elem * n_elem * sizeof(float);\n",
        "\n",
        "  // Alocando matrizes na RAM como sequências de linhas\n",
        "  A = (float *)malloc( tam_mat );\n",
        "  B = (float *)malloc( tam_mat );\n",
        "  C = (float *)malloc( tam_mat );\n",
        "\n",
        "  // Atribuição de valores para as matrizes\n",
        "  // É claro que, para gerar valores desta forma, poderíamos fazer isso na GPU, em paralelo :-)\n",
        "  for(int i=0; i < n_elem * n_elem; i++) {\n",
        "    A[i] = 0.1;\n",
        "    B[i] = 0.2;\n",
        "  }\n",
        "\n",
        "  // Alocação de espaço para as matrizes na GPU\n",
        "\tcudaMalloc((void **)&d_A, tam_mat );\n",
        "\tcudaMalloc((void **)&d_B, tam_mat );\n",
        "\tcudaMalloc((void **)&d_C, tam_mat );\n",
        "\n",
        "  // Cópia dos dados de A e B para d_A e d_B. Não precisa copiar C!\n",
        "\tcudaMemcpy(d_A, A, tam_mat, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, tam_mat, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  // Definição do bloco e da grade\n",
        "  dim3 block;\n",
        "\n",
        "  block.x = 16;\n",
        "  block.y = 16;\n",
        "  block.z = 1;\n",
        "\n",
        "  dim3 grid;\n",
        "  grid.x = (n_elem + block.x -1) / block.x;\n",
        "  grid.y = (n_elem + block.y -1) / block.y;\n",
        "  grid.z = 1;\n",
        "\n",
        "  // Invocação do kernel\n",
        "\tsomaMatrizes <<< grid, block >>> (d_A, d_B, d_C, n_elem );\n",
        "\n",
        "  cudaError_t err = cudaGetLastError();\n",
        "  if (err!= cudaSuccess) {\n",
        "    printf(\"Erro: %s\\n\", cudaGetErrorString(err));\n",
        "    exit(0);\n",
        "  }\n",
        "\n",
        "  // Copia dados resultantes da memória da GPU para a RAM\n",
        "  // Operação de cópia é síncrona: só executará depois de concluída a operação anterior\n",
        "  // na GPU (execução do kernel, neste caso) e só retornará depois de concluída a transferência\n",
        "\tcudaMemcpy(C, d_C, tam_mat, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // nao precisa fazer a sincronizacao abaixo, já que memcpy é síncrona\n",
        "  // cudaDeviceSynchronize();\n",
        "\n",
        "  // Conferindo os valores produzidos\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < n_elem * n_elem; i++)\n",
        "    maxError = max(maxError, abs(C[i]-0.3));\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        "\n",
        "  // Libera memória na GPU\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\tcudaFree(d_C);\n",
        "\n",
        "\t// Libera memória - CPU / RAM\n",
        "\tfree(A);\n",
        "\tfree(B);\n",
        "\tfree(C);\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eQOq236AW2j",
        "outputId": "ee1cfcfc-010e-4bc2-f49a-a22f7978722b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 2dx2d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! 2dx2d -nt 2dx2d.cu ]; then nvcc 2dx2d.cu -o 2dx2d -O3; fi\n",
        "! nvprof --print-gpu-trace ./2dx2d\n",
        "# ! ./2dx2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkZF8xgySda2",
        "outputId": "3946f5bc-41c6-4404-cd84-3ced15f2652f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==469== NVPROF is profiling process 469, command: ./2dx2d\n",
            "Max error: 0.000000\n",
            "==469== Profiling application: ./2dx2d\n",
            "==469== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "423.69ms  87.500ms                    -               -         -         -         -  400.00MB  4.4643GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "511.41ms  86.516ms                    -               -         -         -         -  400.00MB  4.5151GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "597.93ms  31.541ms          (320 320 1)       (32 32 1)        16        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  somaMatrizes(float*, float*, float*, int) [116]\n",
            "629.48ms  264.33ms                    -               -         -         -         -  400.00MB  1.4778GB/s      Device    Pageable     Tesla T4 (0)         1         7  [CUDA memcpy DtoH]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bloco 1D e grade 1D\n",
        "\n",
        "Nesta estratégia de particionamento do cálculos dos elementos, tanto o bloco de *threads* quanto a grade de blocos são organizados em estruturas com 1 dimensão.\n",
        "\n",
        "Como as matrizes já estão linearizadas, é possível fazer um mapeamento direto entre o índice da *thread* e o índice das matrizes.\n"
      ],
      "metadata": {
        "id": "KTPkIJG0bidc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 1dx1d.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define DIM 10240\n",
        "\n",
        "\n",
        "__global__ void somaMatrizes(float *A, float *B, float *C, int dim )\n",
        "{\n",
        "\tunsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "\tif (idx < dim * dim)\n",
        "\t\tC[idx] = A[idx] + B[idx];\n",
        "}\n",
        "\n",
        "\n",
        "int main()\n",
        "{\n",
        "  float *A, *B, *C;          // ponteiros para matrizes na RAM\n",
        "  float *d_A, *d_B, *d_C;    // ponteiros para matrizes na GPU\n",
        "\n",
        "  int n_elem = DIM;\n",
        "  size_t tam_mat = n_elem * n_elem * sizeof(float);\n",
        "\n",
        "  // Alocando matrizes na RAM como sequências de linhas\n",
        "  A = (float *)malloc( tam_mat );\n",
        "  B = (float *)malloc( tam_mat );\n",
        "  C = (float *)malloc( tam_mat );\n",
        "\n",
        "  // Atribuição de valores para as matrizes\n",
        "  // É claro que, para gerar valores desta forma, poderíamos fazer isso na GPU, em paralelo :-)\n",
        "  for(int i=0; i < n_elem * n_elem; i++) {\n",
        "    A[i] = 0.1;\n",
        "    B[i] = 0.2;\n",
        "  }\n",
        "\n",
        "  // Alocação de espaço para as matrizes na GPU\n",
        "\tcudaMalloc((void **)&d_A, tam_mat );\n",
        "\tcudaMalloc((void **)&d_B, tam_mat );\n",
        "\tcudaMalloc((void **)&d_C, tam_mat );\n",
        "\n",
        "  // Cópia dos dados de A e B para d_A e d_B. Não precisa copiar C!\n",
        "\tcudaMemcpy(d_A, A, tam_mat, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, B, tam_mat, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "  // Definição do bloco e da grade\n",
        "  // dim3 block;\n",
        "  // block.x = 32; block.y = 32; block.z = 1;\n",
        "\n",
        "  // dim3 grid;\n",
        "  // grid.x = (n_elem + block.x -1) / block.x;  grid.y = (n_elem + block.y -1) / block.y; grid.z = 1;\n",
        "\n",
        "  int block = 32;\n",
        "  int grid = (n_elem * n_elem + block -1) / block;\n",
        "\n",
        "  // Invocação do kernel\n",
        "\tsomaMatrizes <<< grid, block >>> (d_A, d_B, d_C, n_elem );\n",
        "\n",
        "  cudaError_t err = cudaGetLastError();\n",
        "  if (err!= cudaSuccess) {\n",
        "    printf(\"Erro: %s\\n\", cudaGetErrorString(err));\n",
        "    exit(0);\n",
        "  }\n",
        "\n",
        "  // Copia dados resultantes da memória da GPU para a RAM\n",
        "  // Operação de cópia é síncrona: só executará depois de concluída a operação anterior\n",
        "  // na GPU (execução do kernel, neste caso) e só retornará depois de concluída a transferência\n",
        "\tcudaMemcpy(C, d_C, tam_mat, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // nao precisa fazer a sincronizacao abaixo, já que memcpy é síncrona\n",
        "  // cudaDeviceSynchronize();\n",
        "\n",
        "  // Conferindo os valores produzidos\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < n_elem * n_elem; i++)\n",
        "    maxError = max(maxError, abs(C[i]-0.3));\n",
        "  printf(\"Max error: %f\\n\", maxError);\n",
        "\n",
        "  // Libera memória na GPU\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\tcudaFree(d_C);\n",
        "\n",
        "\t// Libera memória - CPU / RAM\n",
        "\tfree(A);\n",
        "\tfree(B);\n",
        "\tfree(C);\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9W9xhy4gXP-",
        "outputId": "9d562d3d-5f83-4c42-b48f-df8d7c5614ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 1dx1d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! 1dx1d -nt 1dx1d.cu ]; then nvcc 1dx1d.cu -o 1dx1d -O3; fi\n",
        "! nvprof --print-gpu-trace ./1dx1d\n",
        "! echo\n",
        "# ! nvprof ./1dx1d\n",
        "# ! ./1dx1d"
      ],
      "metadata": {
        "id": "j8lGGLt8hSAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd1bf8d-3f8e-4dfb-ef4e-177baacd8792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==1277== NVPROF is profiling process 1277, command: ./1dx1d\n",
            "Max error: 0.000000\n",
            "==1277== Profiling application: ./1dx1d\n",
            "==1277== Profiling result:\n",
            "   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput  SrcMemType  DstMemType           Device   Context    Stream  Name\n",
            "413.50ms  85.487ms                    -               -         -         -         -  400.00MB  4.5694GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "499.22ms  88.854ms                    -               -         -         -         -  400.00MB  4.3962GB/s    Pageable      Device     Tesla T4 (0)         1         7  [CUDA memcpy HtoD]\n",
            "588.08ms  11.450ms        (3276800 1 1)        (32 1 1)        16        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  somaMatrizes(float*, float*, float*, int) [116]\n",
            "599.54ms  257.86ms                    -               -         -         -         -  400.00MB  1.5149GB/s      Device    Pageable     Tesla T4 (0)         1         7  [CUDA memcpy DtoH]\n",
            "\n",
            "Regs: Number of registers used per CUDA thread. This number includes registers used internally by the CUDA driver and/or tools and can be more than what the compiler shows.\n",
            "SSMem: Static shared memory allocated per CUDA block.\n",
            "DSMem: Dynamic shared memory allocated per CUDA block.\n",
            "SrcMemType: The type of source memory accessed by memory operation/copy\n",
            "DstMemType: The type of destination memory accessed by memory operation/copy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Será que a organização das *threads* e dos blocos tem algum impacto no desempenho da execução do *kernel*?\n",
        "\n",
        "Um aspecto a considerar é que o código da função do *kernel* 2dx2d tem mais instruções para o cálculo dos índices do que a versão 1dx1d:\n",
        "\n",
        "```c\n",
        "{ // 2dx2d\n",
        "  unsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  unsigned idy = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  if (idx < dim && idy < dim)\n",
        "    C[idx * dim + idy] = A[idx * dim + idy] + B[idx * dim + idy];\n",
        "}\n",
        "```\n",
        "\n",
        "```c\n",
        "{ // 1dx1d\n",
        "  unsigned idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  if (idx < dim * dim)\n",
        "    C[idx] = A[idx] + B[idx];\n",
        "}\n",
        "```\n"
      ],
      "metadata": {
        "id": "gOqAH9DhtQxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! echo Usando 2d x 2d:\n",
        "! nvprof --print-gpu-trace ./2dx2d 2>&1 | grep somaMatrizes\n",
        "! echo\n",
        "! echo Usando 1d x 1d:\n",
        "! nvprof --print-gpu-trace ./1dx1d 2>&1 | grep somaMatrizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUHvepVet0T8",
        "outputId": "7fb1fd77-f2a0-489a-d96c-c6b95d7d205f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando 2d x 2d:\n",
            "591.46ms  31.546ms          (320 320 1)       (32 32 1)        16        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  somaMatrizes(float*, float*, float*, int) [116]\n",
            "\n",
            "Usando 1d x 1d:\n",
            "600.28ms  11.455ms        (3276800 1 1)        (32 1 1)        16        0B        0B         -           -           -           -     Tesla T4 (0)         1         7  somaMatrizes(float*, float*, float*, int) [116]\n"
          ]
        }
      ]
    }
  ]
}