{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yj_aX7L_VicA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF76EjM3ZQ7r"
      },
      "source": [
        "# PPD: Programação com CUDA\n",
        "\n",
        "Hélio - DC/UFSCar - 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuaVzXKRwwZM"
      },
      "source": [
        "# Criando códigos para GPUs: *kernels*\n",
        "\n",
        "Na programação com CUDA, o fluxo principal do programa continua sendo em CPU, mas é possível transferir parte do processamento para a(s) GPU(s), bem como os dados necessários para esses processamentos.\n",
        "\n",
        "No funcionamento combinado de CPU e GPU, usa-se o termo ***host*** para designar o sistema computacional, e ***device*** para designar a GPU. Assim, fala-se em processamento no *host* e processamento no *device* (dispositivo). Cabe ao código do *host* coordenar as transferência de dados e códigos para o *device*, bem como ativar suas execuções. Os códigos executados no *device* são chamados de ***kernels***.\n",
        "\n",
        "De maneira geral, a programação com CUDA envolve as seguintes etapas:\n",
        "\n",
        "* Declarar e alocar variáveis e espaços de memória para dados na RAM (*host memory*) (para as atividades executando em CPU);\n",
        "* Declarar e alocar variáveis necessárias no espaço de endereçamento da GPU (*device memory*), para os processamentos em GPU;\n",
        "* Inicializar dados no *host*;\n",
        "* Transferir dados do *host* para o *device*;\n",
        "  <br>[ ou Inicializar dados direteramente no *device*; ]\n",
        "* Executar um ou mais *kernels* no *device*;\n",
        "* Transferir os resultados da memória do *device* para a memória do *host*.\n",
        "\n",
        "A declaração e a ativação de códigos para execução em GPU ocorrem dentro do próprio programa. Cada código de GPU (*kernel*) é declarado como uma função que tem o prefixo **\\_\\_global__**. Isso indica ao compilador para gerar código para esta função usando os recursos da arquitetura da GPU.\n",
        "\n",
        "Variáveis declaradas dentro de uma função de *kernel* serão alocadas automaticamente na área de memória do *device*. Essa alocação pode ocorrer em registradores dos processadores da GPU ou em posições de memória, o que é feito pela própria plataforma CUDA.\n",
        "\n",
        "Na ativação da função do *kernel*, especifica-se também a organizacão lógica das *threads* que serão utilizadas na execução deste código. Assim, o **número de instâncias** que irão executar o *kernel* especificado é determinado pelo **número de *threads*** selecionadas na ativação do *kernel*.\n",
        "\n",
        "<!--\n",
        "```\n",
        "// Kernel definition\n",
        "__global__ void VecAdd(float* A, float* B, float* C)\n",
        "{\n",
        "    int i = threadIdx.x;\n",
        "    C[i] = A[i] + B[i];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    ...\n",
        "    // Kernel invocation with N threads\n",
        "    VecAdd<<<1, N>>>(A, B, C);\n",
        "    ...\n",
        "}\n",
        "```\n",
        "-->\n",
        "\n",
        "<br>\n",
        "\n",
        "A ativação do código de um *kernel* em GPU é feita de forma semelhante a uma chamada de função no programa da CPU. O uso dos caracteres \"\"<<< , >>>\"\" após o nome da função serve para indicar o número e a organização lógica dos processadores da GPU. Parâmetros da função do *kernel* são especificados depois dessas informações.  \n",
        "\n",
        "<br>\n",
        "\n",
        "Considerando o código resultante da compilação de um programa CUDA, a ativação de um *kernel* implica que o código binário gerado para os comandos em alto nível de uma função **__global__** contenha instruções do repertório dos processadores da GPU, bem como outras chamadas ao sistema de controle da GPU para transferência de código para o dispositivo e ativação desses códigos com a composição da grade de *threads* desejada.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sobre o código gerado para execução na GPU\n",
        "\n",
        "Além das funções definidas para execução como *kernels* na GPU, que contêm o prefixo \\_\\_global__, outras funções do programa que venham a ser solicitadas pelos *kernels* também precisam ser compiladas tendo em vista o código binário do dispositivo.\n",
        "\n",
        "Para tanto, é preciso introduzir no código de alto nível dessas funções o prefixo ***\\_\\_device\\__***, que indica ao compilador a arquitetura alvo para a geração do código binário.\n",
        "\n",
        "Mas o que mais pode ser utilizado na criação das funções *kernels*?\n",
        "\n",
        "Chamadas de sistema, como a leitura e a escrita em arquivos, por exemplo, não têm sido serem realizadas na GPU.\n",
        "\n",
        "Já funções matemáticas podem ser úteis, mas é claro que são necessárias outras implementações dessas funções específicas para GPUs, ao invés de tentarmos ligar no código a biblioteca padrão **libm**.\n",
        "\n",
        "De maneira relacionada, o uso da função de impressão no terminal (*stdout*) também tem uma versão específica para GPU.\n",
        "\n",
        "<br>\n",
        "\n",
        "A biblioteca com as funções de suporte aos programas é chamada de [**CUDA *runtime***](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-runtime), que pode ser ligada aos programas de forma estática ou dinâmica.\n",
        "\n",
        "## CUDA Runtime\n",
        "\n",
        "    The runtime is implemented in the cudart library, which is linked to the\n",
        "    application, either statically via cudart.lib or libcudart.a, or\n",
        "    dynamically via cudart.dll or libcudart.so.\n",
        "\n",
        "  https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-runtime\n"
      ],
      "metadata": {
        "id": "rLe6WhYAtJY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatted output\n",
        "\n",
        "Pareceu estranho o uso da função ***printf()*** dentro da função (*kernel*) que executa na GPU (*device*)?\n",
        "\n",
        "Pois é, como indicado no manual [[1](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#formatted-output)], há uma versão específica desta função para ser executada na GPU. Assim como na versão original, esta versão para GPU realiza a formação dos parâmetros numa sequência de caracteres para impressão.\n",
        "\n",
        "Quando usada na função de um *kernel*, todas as *threads* que executarem este *kernel* irão gerar dados para impressão. Assim, é possível que o programador decida por executá-la apenas em *threads* específicas, identificadas pelos respectivos índices.\n",
        "\n",
        "Com relação ao volume de impressão, a biblioteca define um *buffer* circular de tamanaho limitado.\n",
        "\n",
        "Já a impressão efetiva dos dados ocorre quando é executada alguma das operações que promovem sincronização, como cudaDeviceSynchronize() e cudaEventSynchronize(), entre outras, além de após a conclusão de operações de transferência de memória, como cudaMemcpy().\n",
        "\n",
        "[1] https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#formatted-output\n"
      ],
      "metadata": {
        "id": "yj_aX7L_VicA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mathematical Functions\n",
        "\n",
        "Outra questão a considerar na definição das funções executadas pelos *kernels* é o uso de funções de biblitecas externas, cujos arquivos binários podem conter código para execução no processador apenas.\n",
        "\n",
        "Para as principais funções matemáticas, contudo, há também versões compiladas também para uso em GPU.\n",
        "\n",
        "<br>\n",
        "\n",
        "https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#mathematical-functions-appendix\n",
        "\n",
        "<br>\n",
        "\n",
        "*The reference manual lists, along with their description, all the functions of the C/C++ standard library mathematical functions that are supported in device code, as well as all intrinsic functions (that are only supported in device code).*\n",
        "\n",
        "*Mathematical functions supported in device code do not set the global errno variable, nor report any floating-point exceptions to indicate errors; thus, if error diagnostic mechanisms are required, the user should implement additional screening for inputs and outputs of the functions. The user is responsible for the validity of pointer arguments. The user must not pass uninitialized parameters to the Mathematical functions as this may result in undefined behavior: functions are inlined in the user program and thus are subject to compiler optimizations.*"
      ],
      "metadata": {
        "id": "N7Uwd5V_yQrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OOarSHfD-XHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entendendo o código gerado pelo compilador CUDA\n",
        "\n",
        "A programação paralela com CUDA consiste na criação de um código que executa em CPU e que controla a operação da(s) GPU(s) para a execução de atividades específicas. Afinal, a GPU pode ser vista como um dispositivo conectado ao computador por alguma interface, como PCI-x.\n",
        "\n",
        "> Como essa interação pode ser um gargalo, há até mecanismos eficientes para a [interligação direta](https://www.nvidia.com/en-us/data-center/nvlink/) entre múltiplas GPUs no mesmo computador.\n",
        "\n",
        "Pensando no código executado em CPU, nos casos mais simples, suas tarefas basicamente consistem em:\n",
        "\n",
        "* alocar áreas de memória RAM para os dados;\n",
        "* ler dados de entrada, comumente de arquivos;\n",
        "* alocar áreas de memória na GPU;\n",
        "* transferir dados necessários para a GPU;\n",
        "* iniciar a execução do código na GPU;\n",
        "* copiar dados produzidos na GPU para a memória RAM\n",
        "\n",
        "<br>\n",
        "\n",
        "  É claro que pode haver variações e repetições dessas etapas, como no caso em que é preciso repetidamente (a) enviar dados para a GPU, (b) ativar o processamento de um kernel na GPU, (c) copiar para a RAM dados produzidos na GPU.\n",
        "\n",
        "<br>\n",
        "\n",
        " No código C com CUDA, as funções destinadas à execução como kernels  em GPU são declaradas com o prefixo ***\\_\\_global__***. Além disso, também é possível criar funções que serão usadas pelos kernels, também executadas  em GPU. Para isso, essas funções devem ser declaradas com o prefixo ***\\_\\_device__***\n",
        "\n"
      ],
      "metadata": {
        "id": "s5z3OGPFtlsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gerando código para a GPU\n",
        "\n",
        "Cabe ao compilador CUDA compilar separadamente as funções destinadas à execução em GPU, gerando o código binário apropriado. Em geral, [nvcc](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html) gera e inclui este código no programa executável, mas também é possível gerar um arquivo binário separado.\n",
        "\n",
        "  O código binário apropriado é transferido para a GPU em tempo de execução, estando pronto para as ativações do kernel.\n",
        "\n",
        "> [ https://docs.nvidia.com/cuda/cuda-binary-utilities/index.html ] <br>\n",
        "> *A CUDA binary (also referred to as cubin) file is an ELF-formatted file which consists of CUDA executable code sections as well as other sections containing symbols, relocators, debug info, etc. By default, the CUDA compiler driver nvcc embeds cubin files into the host executable file. But they can also be generated separately by using the \"-cubin\" option of nvcc. cubin files are loaded at run time by the CUDA driver API.*\n",
        "\n",
        "\n",
        "> *CUDA provides two binary utilities for examining and disassembling cubin files and host executables: cuobjdump and nvdisasm. Basically, cuobjdump accepts both cubin files and host binaries while nvdisasm only accepts cubin files; but nvdisasm provides richer output options.*\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "Os exemplos a seguir realizam a compilação do código da GPU apenas e mostram informações do programa resultante."
      ],
      "metadata": {
        "id": "kjZkD2PyuTVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Veja as seções do programa compilado, salvas num arquivo ELF\n",
        "! nvcc ind.cu -o ind\n",
        "! echo\n",
        "! objdump -h -w ind"
      ],
      "metadata": {
        "id": "C3Kv1PxGt7nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veja informações do arquivo elf gerado com o código da GPU apenas\n",
        "# ! nvcc ind.cu -o ind\n",
        "! nvcc ind.cu -cubin\n",
        "! ls -l ind*\n",
        "! echo\n",
        "! cuobjdump --dump-elf ind.cubin"
      ],
      "metadata": {
        "id": "pja9HI9FuAA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veja o código executável do arquivo binário da GPU\n",
        "# ! nvcc ind.cu -o ind\n",
        "! nvcc ind.cu -cubin\n",
        "! echo\n",
        "! nvdisasm --print-code ind.cubin"
      ],
      "metadata": {
        "id": "4gCKs2RwuETV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geração de valores aleatórios na GPU\n",
        "\n",
        "Considerando a complexidade e o custo computacional para a geração de números aleatórios com distribuições apropriadas, há uma biblioteca específica de CUDA que permite a geração de valores na GPU, de forma paralela e eficiente.\n",
        "\n",
        "Para tanto, contudo, não é preciso gerar uma função de kernel específica, bastando realizar no *host* chamadas às funções de uma biblioteca específica chamada [curand](https://docs.nvidia.com/cuda/curand/index.html).\n",
        "\n",
        "<br>\n",
        "\n",
        "https://docs.nvidia.com/cuda/curand/introduction.html\n",
        "\n",
        "*cuRAND consists of two pieces: a library on the host (CPU) side and a device (GPU) header file. The host-side library is treated like any other CPU library: users include the header file, /include/curand.h, to get function declarations and then link against the library.*\n",
        "\n",
        "*Random numbers can be generated on the device or on the host CPU. For device generation, calls to the library happen on the host, **but the actual work of random number generation occurs on the device**. **The resulting random numbers are stored in global memory on the device**. Users can then call their own kernels to use the random numbers, or they can copy the random numbers back to the host for further processing. For host CPU generation, all of the work is done on the host, and the random numbers are stored in host memory.*\n",
        "\n",
        "<br>\n",
        "\n",
        "O programa a seguir ilustra o uso da biblioteca curand para geração de valores aleatórios na GPU a partir de código executado no *host*.\n",
        "\n",
        "Também é possível usar chamadas da API em *kernels* e funções compiladas para execução na GPU (__device__).\n"
      ],
      "metadata": {
        "id": "7_zYPN-84rHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rand.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <curand.h>\n",
        "\n",
        "int\n",
        "main()\n",
        "{\n",
        "  size_t n = 100;\n",
        "  size_t i;\n",
        "  curandGenerator_t gen;\n",
        "  float *devData, *hostData;\n",
        "\n",
        "  // Aloca espaco para n floats na RAM\n",
        "  hostData = (float *)malloc(n * sizeof(float));\n",
        "\n",
        "  // Aloca espaco para n floats na GPU\n",
        "  cudaMalloc((void **)&devData, n * sizeof(float));\n",
        "\n",
        "  // Cria um gerador de numeros pseuso-aleatorios\n",
        "  curandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT);\n",
        "\n",
        "  // Inicia semente de geracao\n",
        "  curandSetPseudoRandomGeneratorSeed(gen, 1234ULL);\n",
        "\n",
        "  // Gera n floats na GPU\n",
        "  curandGenerateUniform(gen, devData, n);\n",
        "\n",
        "  // Dados gerados na GPU podem ser usados em algum kernel específico, uma\n",
        "  // vez que os dados gerados são salvos na memória da GPU\n",
        "\n",
        "  // Copia numeros gerados da GPU para a RAM\n",
        "  cudaMemcpy(hostData, devData, n * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Exibe valores gerados\n",
        "  printf(\"índice, valor\\n\");\n",
        "  for(i = 0; i < n; i++)\n",
        "    printf(\"%d, %1.4f\\n\", (int)i, hostData[i]);\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  // Libera recursos\n",
        "  curandDestroyGenerator(gen);\n",
        "  cudaFree(devData);\n",
        "\n",
        "  free(hostData);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bFCF90044EI",
        "outputId": "94f21208-805f-4394-a7c7-885c24d92c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing rand.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! rand -nt rand.cu ]; then nvcc rand.cu -o rand -lcurand -O3; fi\n",
        "! ./rand > result.csv\n",
        "! cat ./result.csv"
      ],
      "metadata": {
        "id": "nbWXUS8L484y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}