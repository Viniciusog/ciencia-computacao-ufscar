{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRdH_aT41eoc"
      },
      "source": [
        "# Programação Paralela e Distribuída\n",
        "\n",
        "Hélio - DC/UFSCar - 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hILSvJL812KK"
      },
      "source": [
        "\n",
        "# Usando instruções vetoriais do processador\n",
        "\n",
        "Nos exemplos a seguir, baseados em [1] e [2], ilustra-se o uso de instruções vetoriais do processador. Para tanto, ao invés de programar em Assembly,  usando comandos \"inline\" usa-se o recurso de operações ***intrisinc*** dentro do próprio programa C. Um guia para as instruções instrinsic pode ser visto em [3].\n",
        "\n",
        "<br>\n",
        "\n",
        "[1] https://blog.qiqitori.com/?p=390\n",
        "\n",
        "[2] https://blog.qiqitori.com/2018/05/matrix-multiplication-using-simd-instructions/\n",
        "\n",
        "[3] https://software.intel.com/sites/landingpage/IntrinsicsGuide/\n",
        "\n",
        "    The Intel Intrinsics Guide is an interactive reference tool for Intel intrinsic instructions,\n",
        "    which are C style functions that provide access to many Intel instructions -\n",
        "    including Intel® SSE, AVX, AVX-512, and more - without the need to write assembly code.\n",
        "\n",
        "[4] https://en.wikipedia.org/wiki/Intrinsic_function\n",
        "\n",
        "```\n",
        "In computer software, in compiler theory, an intrinsic function (or built-in function) is a function (subroutine)\n",
        "available for use in a given programming language whose implementation is handled specially by the compiler.\n",
        "Typically, it may substitute a sequence of automatically generated instructions for the original function call,\n",
        "similar to an inline function.[1]\n",
        "Unlike an inline function, the compiler has an intimate knowledge of an intrinsic function\n",
        "and can thus better integrate and optimize it for a given situation.\n",
        "\n",
        "Compilers that implement intrinsic functions generally enable them only when a program requests optimization,\n",
        "otherwise falling back to a default implementation provided by the language runtime system (environment).\n",
        "\n",
        "Intrinsic functions are often used to explicitly implement vectorization and parallelization in languages\n",
        "which do not address such constructs.\n",
        "Some application programming interfaces (API), for example, AltiVec and OpenMP, use intrinsic functions\n",
        "to declare, respectively, vectorizable and multiprocessing-aware operations during compiling.\n",
        "The compiler parses the intrinsic functions and converts them into vector math or multiprocessing\n",
        "object code appropriate for the target platform.\n",
        "Some intrinsics are used to provide additional constraints to the optimizer, such as values\n",
        "a variable cannot assume.[2]\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "**PS**: para quem quiser examinar como é o cógigo assembly gerado por diferentes compiladores e opções de otimização, uma ferramenta interessante é https://godbolt.org/. Com ela, basta digitar o código C, selecionar o compilador e as opções, e examinar o código gerado. Dá para aprender bastante examinando as instruções vetoriais geradas pelas pelo código otimizado!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testes com godbolt.org\n",
        "```\n",
        "# include <stdio.h>\n",
        "\n",
        "#define TAM 1024\n",
        "\n",
        "// #define SUM\n",
        "// #define REDUCTION\n",
        "// #define MULT\n",
        "#define IKJ\n",
        "\n",
        "#if defined MULT || defined IKJ\n",
        " int a[TAM][TAM], b[TAM][TAM], c[TAM][TAM];\n",
        "# endif\n",
        "\n",
        "#if defined SUM || defined REDUCTION\n",
        " int a[TAM], b[TAM], c[TAM];\n",
        "#endif\n",
        "\n",
        "int main()\n",
        "{\n",
        "#ifdef SUM\n",
        "    for(int i=0; i < TAM; i++)\n",
        "        c[i] = a[i] * b[i];\n",
        "#endif\n",
        "\n",
        "#ifdef REDUCTION\n",
        "    double sum = 0.;\n",
        "    for (int i=0; i < TAM; i++)\n",
        "        sum += a[i] * b[i];\n",
        "\n",
        "    printf(\"sum: %d\\n\",sum);\n",
        "#endif\n",
        "\n",
        "#ifdef MULT\n",
        "    for (int i=0; i < TAM; i++)\n",
        "        for (int j=0; j < TAM; j++)\n",
        "            for (int k=0; k < TAM; k++)\n",
        "                c[i][j]+= a[i][k]*b[k][j];\n",
        "#endif\n",
        "\n",
        "// Nas otimizações do compilador, experimente -O3 e -mavx !!!\n",
        "#ifdef IKJ\n",
        "    for (int i=0; i < TAM; i++)\n",
        "        for (int k=0; k < TAM; k++)\n",
        "            for (int j=0; j < TAM; j++)\n",
        "                c[i][j]+= a[i][k]*b[k][j];\n",
        "#endif\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "onEtmGbLSQBW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4n1_q444XQf"
      },
      "source": [
        "# Soma de elementos de um vetor\n",
        "\n",
        "O programa a seguir usa instruções *intrinsic* para fazer uma operação de soma de 4 valores float em uma única operação.\n",
        "\n",
        "As opearações realizadas usam registradores internos do processador, com 128 bits, que podem trabalhar com até 4 valores floats (32 bits) de uma só vez.\n",
        "\n",
        "Para tanto, os valores que serão manipulados devem estar armazenados de forma contígua na memória, como em um vetor com 4 posições, para que dali possam ser copiados para registradores específicos no processador, onde são feitas as operações. Os dados são então copiados de volta para a memória.\n",
        "\n",
        "Neste caso, serão usadas extensões do repertório de instruções de processadorex x86/64 pertencentes à tecnologia **SSE** , incluindo operações de cópia de valores da memória em registradores ([_mm_loadu_ps](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_loadu&techs=SSE&expand=3407)), soma vetorial ([_mm_add_ps](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_add_ps&expand=3407,133&techs=SSE)), e cópia de valor de registrador para a memória ([_mm_store_ps](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_store_ps&expand=3407,133,5588&techs=SSE,SSE2)).\n",
        "\n",
        "Nessas operações, o sufixo _ps indica opearação em precisão simples, portanto considerando valores float, de 4 bytes.\n",
        "\n",
        "Fez sentido?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRBZWUzrAZfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60e740e-0980-4d9a-dd2b-b776c0908077"
      },
      "source": [
        "%%writefile sse_add.c\n",
        "\n",
        "// https://blog.qiqitori.com/?p=390\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <xmmintrin.h> // Need this in order to be able to use the SSE \"intrinsics\"\n",
        "                       // (which provide access to instructions without writing assembly)\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "   float a[4], b[4], result[4]; // a and b: input, result: output\n",
        "   __m128 va, vb, vresult;      // these vars will \"point\" to SIMD registers\n",
        "\n",
        "\n",
        "   // initialize arrays (just {0,1,2,3})\n",
        "   for (int i = 0; i < 4; i++) {\n",
        "      a[i] = (float)i;\n",
        "      b[i] = (float)i;\n",
        "   }\n",
        "\n",
        "   // load arrays into SIMD registers\n",
        "   va = _mm_loadu_ps(a);\n",
        "   vb = _mm_loadu_ps(b);\n",
        "\n",
        "   // add them together\n",
        "   vresult = _mm_add_ps(va, vb);\n",
        "\n",
        "   // store contents of SIMD register into memory\n",
        "   _mm_storeu_ps(result, vresult);\n",
        "\n",
        "   // print out result\n",
        "   for (int i = 0; i < 4; i++) {\n",
        "      printf(\"%f\\n\", result[i]);\n",
        "   }\n",
        "\n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sse_add.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Aq6fGHKAlgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1dca34-b460-42b0-e058-9dd09625e4f4"
      },
      "source": [
        "! gcc -Wall sse_add.c -o sse_add && ./sse_add"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.000000\n",
            "2.000000\n",
            "4.000000\n",
            "6.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1aZ3FREU3r9"
      },
      "source": [
        "Segue outro programa equivalente, agora usando extensões AVX.\n",
        "\n",
        "Na compilação deste programa com **gcc**, é preciso incluir o parâmetro ***-mavx***.\n",
        "\n",
        "https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8WqeY1bAspX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847b5eeb-12ce-4685-ab8f-5cac5dc7de94"
      },
      "source": [
        "%%writefile avx_add.c\n",
        "\n",
        "// https://blog.qiqitori.com/?p=390\n",
        "\n",
        "#include <immintrin.h>  // Need this in order to be able to use the AVX \"intrinsics\"\n",
        "                        //(which provide access to instructions without writing assembly)\n",
        "#include <stdio.h>\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "   // Intel documentation states that we need 32-byte alignment to use _mm256_load_ps/_mm256_store_ps\n",
        "   float a[8] __attribute__ ((aligned (32)));\n",
        "\n",
        "   // GCC's syntax makes this look harder than it is:\n",
        "   // https://gcc.gnu.org/onlinedocs/gcc-6.4.0/gcc/Common-Variable-Attributes.html#Common-Variable-Attributes\n",
        "   float b[8] __attribute__ ((aligned (32)));\n",
        "\n",
        "   float result[8]  __attribute__ ((aligned (32)));\n",
        "\n",
        "   __m256 va, vb, vresult; // __m256 is a 256-bit datatype, so it can hold 8 32-bit floats\n",
        "\n",
        "   // initialize arrays (just {0,1,2,3,4,5,6,7})\n",
        "   for (int i = 0; i < 8; i++) {\n",
        "      a[i] = (float)i;\n",
        "      b[i] = (float)i;\n",
        "   }\n",
        "\n",
        "   // load arrays into SIMD registers\n",
        "   va = _mm256_load_ps(a); // https://software.intel.com/en-us/node/694474\n",
        "   vb = _mm256_load_ps(b); // same\n",
        "\n",
        "   // add them together\n",
        "   vresult = _mm256_add_ps(va, vb); // https://software.intel.com/en-us/node/523406\n",
        "\n",
        "   // store contents of SIMD register into memory\n",
        "   _mm256_store_ps(result, vresult); // https://software.intel.com/en-us/node/694665\n",
        "\n",
        "   // print out result\n",
        "   for (int i = 0; i < 8; i++) {\n",
        "      printf(\"%f\\n\", result[i]);\n",
        "   }\n",
        "\n",
        "   return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting avx_add.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBLIIImrV08a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bace235d-d140-4fcc-985e-f41a88c06dbb"
      },
      "source": [
        "! gcc -Wall avx_add.c -o avx_add -mavx && ./avx_add"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.000000\n",
            "2.000000\n",
            "4.000000\n",
            "6.000000\n",
            "8.000000\n",
            "10.000000\n",
            "12.000000\n",
            "14.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PsVZ5QBXsKE"
      },
      "source": [
        "# Multiplicação de matrizes\n",
        "\n",
        "Mais um exemplo de uso de extensões das instruções do processador (***SSE3***) com chamadas *intrinsics*, desta vez realizando a multiplicação de matrizes.\n",
        "\n",
        "Nesse caso, como são usadas instruções que realizam operações sobre 4 floats de cada vez, há dois aspectos importantes a considerar:\n",
        "\n",
        "* primeiro, é preciso que a matriz B esteja no formato transposto para que os dados estejam em posições contíguas da memória\n",
        "* as matrizes A e B são percorridas em blocos de 4 elementos de cada vez; daí o incremento de k em 4\n",
        "\n",
        "Outro aspecto importante é como somar os resultados das multiplicações. Afinal, 4 elementos foram multiplicados (2 a 2) em paralelo, e armazenados em 4 posições distintas. Como somar esses 4 valores agora?\n",
        "\n",
        "Para isso existe uma operação chamada ***hadd*** (*horizontal add*). Essa operação soma os 2 primeiros elementos e armazena o resultado no lugar do 1o. Ao mesmo tempo, soma os elementos 3 e 4 e salva o resultado no lugar do 2o.\n",
        "\n",
        "Se repetirmos essa operação com o mesmo operador, o resultado é que na posiçãdo do primeiro elemento estará a soma do 1o e o 2o, que continham 1+2 e 3+4.\n",
        "\n",
        "Pronto!\n",
        "\n",
        "Vale observar que os dados não são alinhados na memória, daí as operações _u_.\n",
        "\n",
        "E então, fez sentido?\n",
        "\n",
        "Ah, na compilação, é preciso prover o parâmetro -msse3, para ativar o uso dessa extensão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4c_6DvjD1YT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1645c0-f8ff-4188-dac4-a69be2ccade8"
      },
      "source": [
        "%%writefile mm_sse_unaligned.c\n",
        "\n",
        "#include <x86intrin.h>\n",
        "// #include <xmmintrin.h>      // para _mm_loadu_ps, _mm_mul_ps\n",
        "// #include <pmmintrin.h>      // para _mm_hadd_ps\n",
        "// #include <xmmintrin.h>      // para _mm_cvtss_f32\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "  float *matrix_a = malloc(1024*1024*sizeof(float));\n",
        "  float *matrix_b = malloc(1024*1024*sizeof(float));\n",
        "  float result[1024][1024];\n",
        "  __m128 va, vb, vresult;\n",
        "\n",
        "  // initialize matrix_a and matrix_b\n",
        "  for (int i = 0; i < 1048576; i++) {\n",
        "    *(matrix_a+i) = 0.1f;\n",
        "    *(matrix_b+i) = 0.2f;\n",
        "  }\n",
        "  // initialize result matrix - poderia substituir por memset()...\n",
        "  for (int i = 0; i < 1024; i++) {\n",
        "    for (int j = 0; j < 1024; j++) {\n",
        "      result[i][j] = 0;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < 1024; i++) {\n",
        "    for (int j = 0; j < 1024; j++) {\n",
        "      for (int k = 0; k < 1024; k += 4) {\n",
        "        // load\n",
        "        va = _mm_loadu_ps(matrix_a+(i*1024)+k); // matrix_a[i][k]\n",
        "        vb = _mm_loadu_ps(matrix_b+(j*1024)+k); // matrix_b[j][k]\n",
        "\n",
        "        // multiply\n",
        "        vresult = _mm_mul_ps(va, vb);\n",
        "\n",
        "        // add\n",
        "        // essa primeira operação soma os elementos (floats) 1 e 2 e os armazena\n",
        "        // na posição 1, e soma 3 e 4, salvando o resultado na posição 2.\n",
        "        vresult = _mm_hadd_ps(vresult, vresult);\n",
        "        // repetindo a operação, teremos a soma de 1 e 2 em 1!\n",
        "        vresult = _mm_hadd_ps(vresult, vresult);\n",
        "\n",
        "        // store\n",
        "        result[i][j] += _mm_cvtss_f32(vresult);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < 1024; i++) {\n",
        "    for (int j = 0; j < 1024; j++) {\n",
        "      printf(\"%f \", result[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm_sse_unaligned.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP1w_hXsAsRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624f834f-1dbe-487a-a690-a66e2a5421e5"
      },
      "source": [
        "# ! gcc -Wall mm_sse_unaligned.c -o mm_sse_unaligned -O3 -msse3 -fopt-info-optall-optimized -ftree-vectorize\n",
        "#\n",
        "# -fopt-info-vec-missed: Detailed info about loops not being vectorized, and a lot of other detailed information.\n",
        "# ! gcc mm_sse_unaligned.c -o mm_sse_unaligned -msse3 -O3 -fopt-info-vec-missed\n",
        "#\n",
        "# -fopt-info-vec-note: Detailed info about all loops and optimizations being done.\n",
        "# ! gcc mm_sse_unaligned.c -o mm_sse_unaligned -msse3 -O3 -fopt-info-vec-note\n",
        "#\n",
        "! gcc -O3 -fopt-info-optall-optimized -msse3 -o mm_sse_unaligned mm_sse_unaligned.c\n",
        "! time ./mm_sse_unaligned > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm_sse_unaligned.c:56:5: optimized:   Inlining printf/5690 into main/5698 (always_inline).\n",
            "mm_sse_unaligned.c:54:7: optimized:   Inlining printf/5690 into main/5698 (always_inline).\n",
            "mm_sse_unaligned.c:47:25: optimized:   Inlining _mm_cvtss_f32/441 into main/5698 (always_inline).\n",
            "mm_sse_unaligned.c:44:19: optimized:   Inlining _mm_hadd_ps/714 into main/5698 (always_inline).\n",
            "mm_sse_unaligned.c:42:19: optimized:   Inlining _mm_hadd_ps/714 into main/5698 (always_inline).\n",
            "mm_sse_unaligned.c:37:19: optimized:   Inlining _mm_mul_ps/337 into main/5698 (always_inline).\n",
            "mm_sse_unaligned.c:34:14: optimized:   Inlining _mm_loadu_ps/436 into main/5698 (always_inline).\n",
            "mm_sse_unaligned.c:33:14: optimized:   Inlining _mm_loadu_ps/436 into main/5698 (always_inline).\n",
            "mm_sse_unaligned.c:23:21: optimized: Loop nest 2 distributed: split to 0 loops and 1 library calls.\n",
            "mm_sse_unaligned.c:18:21: optimized: loop vectorized using 16 byte vectors\n",
            "\n",
            "real\t0m1.121s\n",
            "user\t0m1.098s\n",
            "sys\t0m0.008s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7TxLAUAmLm7"
      },
      "source": [
        "O próximo exemplo de uso de extensões das instruções do processador realiza a multiplicação de matrizes usando instruções avx256.\n",
        "\n",
        "Com essas extensões, usamos agora registradores com 256 bits, que são suficientes para armazenar 8 (!) valores float em sequência. Analogamente, a operação de multiplicação ([_mm256_mul_ps](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=3407,133,5588,3333,3333,2946,3928,3407,2946,1890,3931&text=_mm256_mul_ps)) realiza 8 multiplicações em ponto flutuante com precisão simples (float) de uma só vez.\n",
        "\n",
        "No código, embora a multiplicação seja feita em 8 floats (256 bits) de cada vez, as opearções de soma são feitas em 2 etapas com 128 bits cada. Isso é feito usando máscaras para pegar os valores mais e menos significativos dos 256 bits de cada vez.\n",
        "\n",
        "Embora exista uma instrução que realize somas de 8 floats de uma só vez ([_mm256_hadd_ps](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=3407,133,5588,3333,3333,3928,3407,2946,1890,3931,2946,2947&text=_mm256_hadd_ps&techs=AVX2)), ela não resolve o problema de agregá-los num valor único.\n",
        "\n",
        "Aspectos importantes a considerar:\n",
        "\n",
        "* primeiro, é preciso que a matriz B esteja no formato transposto\n",
        "* as matrizes A e B são percorridas em blocos de 8 elementos de cada vez; daí o incremento de k em 8\n",
        "\n",
        "Vale observar que os dados não são alinhados na memória, daí as operações _u_.\n",
        "\n",
        "Ah, na compilação, é preciso prover o parâmetro ***-mavx***, para ativar o uso dessa extensão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92v8UEBEEtTK",
        "outputId": "a145b3f3-5eb8-4d16-c2c5-2619561310a1"
      },
      "source": [
        "%%writefile mm_avx256_unaligned.c\n",
        "\n",
        "#include <x86intrin.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "  float *matrix_a = malloc(1024*1024*sizeof(float));\n",
        "  float *matrix_b = malloc(1024*1024*sizeof(float));\n",
        "  float result[1024][1024];\n",
        "  __m256 va, vb, vtemp;\n",
        "  __m128 vlow, vhigh, vresult;\n",
        "\n",
        "  // initialize matrix_a and matrix_b\n",
        "  for (int i = 0; i < 1048576; i++) {\n",
        "    *(matrix_a+i) = 0.1f;\n",
        "    *(matrix_b+i) = 0.2f;\n",
        "  }\n",
        "  // initialize result matrix\n",
        "  for (int i = 0; i < 1024; i++) {\n",
        "    for (int j = 0; j < 1024; j++) {\n",
        "      result[i][j] = 0;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < 1024; i++) {\n",
        "    for (int j = 0; j < 1024; j++) {\n",
        "      for (int k = 0; k < 1024; k += 8) {\n",
        "        // load\n",
        "        va = _mm256_loadu_ps(matrix_a+(i*1024)+k); // matrix_a[i][k]\n",
        "        vb = _mm256_loadu_ps(matrix_b+(j*1024)+k); // matrix_b[j][k]\n",
        "\n",
        "        // multiply\n",
        "        vtemp = _mm256_mul_ps(va, vb);\n",
        "\n",
        "        // add\n",
        "        // extract higher four floats\n",
        "        vhigh = _mm256_extractf128_ps(vtemp, 1); // high 128\n",
        "        // add higher four floats to lower floats\n",
        "        vresult = _mm_add_ps(_mm256_castps256_ps128(vtemp), vhigh);\n",
        "        // horizontal add of that result\n",
        "        vresult = _mm_hadd_ps(vresult, vresult);\n",
        "        // another horizontal add of that result\n",
        "        vresult = _mm_hadd_ps(vresult, vresult);\n",
        "\n",
        "        // store\n",
        "        result[i][j] += _mm_cvtss_f32(vresult);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < 1024; i++) {\n",
        "    for (int j = 0; j < 1024; j++) {\n",
        "      printf(\"%f \", result[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm_avx256_unaligned.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTQ4sfOSEzgD",
        "outputId": "fbf22c01-3eb9-462d-ec0a-d03f663141d4"
      },
      "source": [
        "! gcc -O3 -fopt-info-optall-optimized -mavx -o mm_avx256_unaligned mm_avx256_unaligned.c\n",
        "! time ./mm_avx256_unaligned > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm_avx256_unaligned.c:57:5: optimized:   Inlining printf/5690 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:55:7: optimized:   Inlining printf/5690 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:48:25: optimized:   Inlining _mm_cvtss_f32/441 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:45:19: optimized:   Inlining _mm_hadd_ps/714 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:43:19: optimized:   Inlining _mm_hadd_ps/714 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:41:19: optimized:   Inlining _mm_add_ps/335 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:41:19: optimized:   Inlining _mm256_castps256_ps128/999 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:39:17: optimized:   Inlining _mm256_extractf128_ps/883 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:35:17: optimized:   Inlining _mm256_mul_ps/856 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:32:14: optimized:   Inlining _mm256_loadu_ps/920 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:31:14: optimized:   Inlining _mm256_loadu_ps/920 into main/5698 (always_inline).\n",
            "mm_avx256_unaligned.c:21:21: optimized: Loop nest 2 distributed: split to 0 loops and 1 library calls.\n",
            "mm_avx256_unaligned.c:16:21: optimized: loop vectorized using 32 byte vectors\n",
            "\n",
            "real\t0m1.120s\n",
            "user\t0m1.090s\n",
            "sys\t0m0.013s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@h To do: e o ikj?\n",
        "Gera somas parciais, que podem prover melhor desempenho ainda..."
      ],
      "metadata": {
        "id": "XCiL_WpE7NBM"
      }
    }
  ]
}