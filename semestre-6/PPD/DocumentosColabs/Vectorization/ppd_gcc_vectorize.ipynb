{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDMVDCnXF9WR"
      },
      "source": [
        "# Programação Paralela e Distribuída\n",
        "\n",
        "Hélio - DC/UFSCar - 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processamento vetorial em CPU com instruções SIMD\n",
        "\n",
        "De acordo com a [taxonomia de Flyyn](https://en.wikipedia.org/wiki/Flynn%27s_taxonomy), SIMD (*Single Instruction, Multiple Data*) é um modo de execução que está associado à realização simultânea da mesma operação sobre diferentes dados (paralelismo de dados).  \n",
        "\n",
        "Originalmente, este recurso surgiu em alguns supercomputadores vetoriais na década de 1970, e trata-se de uma forma de paralelismo com granularidade fina.\n",
        "\n",
        "Com a evolução das tecnologias de construção de processadores e o potencial para otimização de operações aritméticas em estruturas vetoriais, comuns em muitas aplicações, CPUs de estações de trabalho passaram também a oferecer instruções para manipulação de dados no modelo SIMD.\n",
        "\n",
        "Na linha dos processadores dos PCs, por exemplo, essa tecnologia surgiu no final da década 1990, com as extensões MMX, seguindo-se com a criação de outras versões desse recurso, com suporte para manipular mais dados e com mais bits ao mesmo tempo. Outros processadores também têm recursos equivalentes, chamados de instruções de **vetorização** (*vectorization*) [1].\n",
        "\n",
        "Basicamente, essas extensões incluem registradores adicionais, mais longos, e uma lógica de circuito que permite realizar algumas operações aritméticas sobre várias partes desses registradores ao mesmo tempo.  Ou seja, operar no modo SIMD.\n",
        "\n",
        "Há várias formas para se explorar os recursos de vetorização de um processador, começando por indicar ao compilador que, se possível, faça isso na geração de código.\n",
        "\n",
        "\n",
        "[1] [https://en.wikipedia.org/wiki/Automatic_vectorization](https://en.wikipedia.org/wiki/Automatic_vectorization)\n",
        "\n"
      ],
      "metadata": {
        "id": "VcNvrp7Q0t1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Identificando extensões de suporte à vetorização\n",
        "\n",
        "Como ilustrado em [2], para usar os recursos de vetorização, é preciso que tanto o processador quanto o compilador disponíveis tenham suporte. Os comandos a seguir ilustram esta verificação.\n",
        "\n",
        "[2] [https://tech.io/playgrounds/283/sse-avx-vectorization/prerequisites](https://tech.io/playgrounds/283/sse-avx-vectorization/prerequisites)\n",
        "\n",
        "```\n",
        "In the CPU flag capabilities, we'll search for the avx flag. This identifies the CPU as AVX compatible.\n",
        "\n",
        "If you have avx2 that means the CPU allows AVX2 extensions. AVX is enough to have 8x32bit float vectors.\n",
        "\n",
        "AVX2 adds 256bits vectors for integers (8x32bit integers for example).\n",
        "Nevertheless, 256bit integer vectors seem to be executed the same as two 128bit vectors,\n",
        "so performance is not greatly improved from SSE 128bit integer vectors.\n",
        "\n",
        "In the GCC capabilities we'll search for the #define __AVX__ 1 pragma.\n",
        "This indicates that the AVX branches will be enabled.\n",
        "\n",
        "Alway use -march=native or -mavx !! If you run GCC without the correct march you won't get the __AVX__ flag!!!\n",
        "Default GCC parameters are generic, and without the flag it won't enable AVX even if the CPU is AVX capable.\n",
        "\n",
        "Finally, we recheck that Linux Kernel is 2.6.30 or greater. A kernel 4.4.0 or greater is ideal.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ouH1b2c7AlT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CPU flag detection\n",
        "! echo \"** Getting CPU flag capabilities and number of cores\"\n",
        "! cat /proc/cpuinfo  | egrep \"(flags|model name|vendor)\" | sort | uniq -c\n",
        "# Compiler capabilities. -march=native is required!\n",
        "! echo; echo \"** Getting GCC capabilities\"\n",
        "! gcc -march=native -dM -E - < /dev/null | egrep \"SSE|AVX\" | sort\n",
        "# OS kernel version\n",
        "! echo; echo \"** Getting OS Kernel Version\"\n",
        "! uname -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niT4Px_LA3FU",
        "outputId": "74bfceb1-223b-4724-e0c9-a1c387085c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Getting CPU flag capabilities and number of cores\n",
            "      2 flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "      2 model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "      2 vendor_id\t: GenuineIntel\n",
            "\n",
            "** Getting GCC capabilities\n",
            "#define __AVX__ 1\n",
            "#define __AVX2__ 1\n",
            "#define __MMX_WITH_SSE__ 1\n",
            "#define __SSE__ 1\n",
            "#define __SSE2__ 1\n",
            "#define __SSE2_MATH__ 1\n",
            "#define __SSE3__ 1\n",
            "#define __SSE4_1__ 1\n",
            "#define __SSE4_2__ 1\n",
            "#define __SSE_MATH__ 1\n",
            "#define __SSSE3__ 1\n",
            "\n",
            "** Getting OS Kernel Version\n",
            "Linux a17106b501e9 5.15.120+ #1 SMP Wed Aug 30 11:19:59 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkPPQTUzF0Ov"
      },
      "source": [
        "# Auto-vetorização usando suporte do compilador\n",
        "\n",
        "Os exemplos apresentados neste documento são baseados nos materiais a seguir, que ilustram aspectos da auto-vetorização realizada pelo compilador.\n",
        "\n",
        "https://blog.qiqitori.com/2018/05/matrix-multiplication-using-gccs-auto-vectorization/\n",
        "\n",
        "https://www.codingame.com/playgrounds/283/sse-avx-vectorization/autovectorization\n",
        "\n",
        "Há também informações extraídas do manual do compilador gcc.\n",
        "\n",
        "<br>\n",
        "\n",
        "Para os testes, será usado um programa simples de multiplicação de matrizes, com cálculo percorrendo as colunas da matriz B, e uma versão que considera que a matriz B está **transposta**, de forma que os elementos originais das colunas podem ser obtidos sequencialmente, percorrendo as linhas da matriz B.\n",
        "\n",
        "De maneira geral, o ojbetivo desses testes é avaliar a **capacidade do compilador** em utilizar as instruções vetoriais do processador na geração de código.\n",
        "\n",
        "Nesse exemplo, não há dicas do programador via **#pragmas**, apenas a passagem de parâmetros na compilação solicitando a aplicação das técnicas de otimização que exploram, entre outras coisas, a vetorização."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py_5VL959o9q",
        "outputId": "5ff9f1b8-bbf2-4e69-d5ac-8e2a59adafda"
      },
      "source": [
        "%%writefile mm.c\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define TAM 1024\n",
        "\n",
        "float matrix_a[TAM][TAM];\n",
        "float matrix_b[TAM][TAM];\n",
        "float matrix_c[TAM][TAM];\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  int i,j,k;\n",
        "\n",
        "  for (i = 0; i < TAM; i++)      // inicia matrizes\n",
        "    for (j = 0; j < TAM; j++) {\n",
        "      matrix_a[i][j] = 0.1f;\n",
        "      matrix_b[i][j] = 0.2f;\n",
        "      matrix_c[i][j] = 0.0f;       // pode ser substituído por memset (0...)\n",
        "    }\n",
        "\n",
        "  for (i=0; i < TAM; i++)      // percorre as linhas de A para calcular linhas de C\n",
        "    for (j=0; j < TAM; j++)    // percorre as colunas de B para calcular colunas de C\n",
        "      for (k=0; k < TAM; k++)  // percorre as colunas da linha de A e as linhas da coluna de B\n",
        "        matrix_c[i][j] += matrix_a[i][k]*matrix_b[k][j];\n",
        "\n",
        "  for (i=0; i < TAM; i++) {\n",
        "    for (j=0; j < TAM; j++)\n",
        "      printf(\"%f \", matrix_c[i][j]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        " }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgNJ0QHtIAX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05dc85c-bbe0-4611-d3d8-cbfcff5760a9"
      },
      "source": [
        "# Compilação do programa\n",
        "! gcc -Wall -o mm mm.c\n",
        "! time ./mm > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t0m13.665s\n",
            "user\t0m13.526s\n",
            "sys\t0m0.014s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-kxFwn0eD62"
      },
      "source": [
        "Será que há otimizações que o compilador possa fazer para gerar código mais eficiente, que resulte em menor tempo de conclusão?\n",
        "\n",
        "No bloco a seguir, o código da multiplicação, mostrado acima (mm.c) será compilado usando apenas diferentes valores para o parâmetro de otimização do compilador.\n",
        "\n",
        "O programa gerado em cada caso é executado 2 vezes via comando ***time***, que vai medir os tempos de execução.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HdiM91G3z-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f86e7b-fe26-411e-9de0-61634e05c1f6"
      },
      "source": [
        "! for i in {0,1,2,3}; do \\\n",
        "    echo Compilando com -O$i && \\\n",
        "    if [ ! mm$i -nt mm.c ]; then gcc -O$i mm.c -o mm$i ; fi && \\\n",
        "    time -p ./mm$i > /dev/null && echo && \\\n",
        "    time -p ./mm$i > /dev/null && echo ; \\\n",
        "  done"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compilando com -O0\n",
            "real 14.93\n",
            "user 14.76\n",
            "sys 0.01\n",
            "\n",
            "real 14.13\n",
            "user 14.00\n",
            "sys 0.01\n",
            "\n",
            "Compilando com -O1\n",
            "real 4.54\n",
            "user 4.50\n",
            "sys 0.00\n",
            "\n",
            "real 5.05\n",
            "user 4.97\n",
            "sys 0.00\n",
            "\n",
            "Compilando com -O2\n",
            "real 4.33\n",
            "user 4.26\n",
            "sys 0.01\n",
            "\n",
            "real 4.37\n",
            "user 4.33\n",
            "sys 0.00\n",
            "\n",
            "Compilando com -O3\n",
            "real 1.41\n",
            "user 1.39\n",
            "sys 0.00\n",
            "\n",
            "real 1.99\n",
            "user 1.93\n",
            "sys 0.01\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01DwT4mte_Pi"
      },
      "source": [
        "Como se pode ver, as diferenças com a otimização são MUITO significativas em relação ao código não otimizado!\n",
        "\n",
        "Mas quais otimizações será que foram aplicadas pelo compilador na geração do código?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehCOBF4rfCn8"
      },
      "source": [
        "# Usando otimizações específicas de vetorização\n",
        "\n",
        "Nos blocos a seguir, um parâmetro a mais é usando na compilação do programa, para pedir ao compilador que indique quais otimizações foram aplicadas na geração do código. Com **gcc**, isso é feito com o parâmetro ***-fopt-info-optall-optimized***.\n",
        "\n",
        "Na linha de comando, é passado o parâmetro ***-O3***, que explicita o nível de otimização 3, e o parâmetro ***-ftree-vectorize***, que indica ao compilador para tentar aplicar as otimizações de *loops*. O parâmetro ***-ftree-vectorizer-verbose=x*** indica o nível de detalhes exibidos sobre a aplicação desta técnica, e o parâmetro ***-fopt-info-optall-optimized*** indica as otimizações aplicadas.\n",
        "\n",
        "\n",
        "Ah, para saber mais sobre as opções de otimização do gcc, veja: [https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html)\n",
        "\n",
        "<br>\n",
        "\n",
        "```\n",
        "-ftree-vectorize : Perform vectorization on trees.\n",
        "  This flag enables -ftree-loop-vectorize and -ftree-slp-vectorize if not explicitly specified.\n",
        "\n",
        "-ftree-loop-vectorize : Perform loop vectorization on trees.\n",
        "  This flag is enabled by default at -O2 and by -ftree-vectorize, -fprofile-use, and -fauto-profile.\n",
        "\n",
        "-ftree-slp-vectorize : Perform basic block vectorization on trees.\n",
        "  This flag is enabled by default at -O2 and by -ftree-vectorize, -fprofile-use, and -fauto-profile.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ-X0VVI-w1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1396e35-4d2d-4fa0-d515-91083b1cb216"
      },
      "source": [
        "# Experimentando otimizações de vetorização pelo compilador\n",
        "# -ftree-vectorize is a simple alias to -ftree-loop-vectorize + -ftree-slp-vectorize\n",
        "! gcc -g mm.c -o mm -O3 -fopt-info-optall-optimized -ftree-vectorize -ftree-vectorizer-verbose=5\n",
        "! time ./mm > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm.c:29:5: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mm.c:28:7: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mm.c:14:17: optimized: Loop nest 1 distributed: split to 2 loops and 1 library calls.\n",
            "mm.c:22:17: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "\n",
            "real\t0m1.390s\n",
            "user\t0m1.362s\n",
            "sys\t0m0.013s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPeJsnWToHzG"
      },
      "source": [
        "Experimentando mais com as opções de otimização, é possível verificar tanto quais otimizações foram aplicadas quanto aquelas que não foram, incluindo os motivos que impediram a paralelização.\n",
        "\n",
        "O parâmetro ***-fopt-info-vec***, ou ***-fopt-info-vec-optimized***, exibe informações específicas sobre os *loops* que foram vetorizados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRybubGXmXpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c4c712-348c-442b-bc7c-003161552a53"
      },
      "source": [
        "# -fopt-info-vec or -fopt-info-vec-optimized: The compiler will log which loops (by line N°) are being vector optimized.\n",
        "# ! gcc mm.c -o mm -O3 -fopt-info-vec-optimized\n",
        "! gcc mm.c -o mm -O3 -fopt-info-vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm.c:22:17: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:15:19: optimized: loop vectorized using 16 byte vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGGFms79okws"
      },
      "source": [
        "Já o parâmetro ***-fopt-info-vec-missed*** indica as oportunidades buscadas mas que não puderam ser exploradas, associadas aos motivos encontrados.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eifYX4Pln3qF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b710854-3ede-4c1b-cef6-6897e6adc254"
      },
      "source": [
        "# -fopt-info-vec-missed: Detailed info about loops not being vectorized, and a lot of other detailed information.\n",
        "! gcc mm.c -o mm -O3 -fopt-info-vec-missed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm.c:26:15: missed: couldn't vectorize loop\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "mm.c:27:17: missed: couldn't vectorize loop\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "mm.c:21:15: missed: couldn't vectorize loop\n",
            "mm.c:21:15: missed: not vectorized: multiple nested loops.\n",
            "mm.c:23:19: missed: couldn't vectorize loop\n",
            "mm.c:23:19: missed: outer-loop already vectorized.\n",
            "mm.c:14:17: missed: couldn't vectorize loop\n",
            "mm.c:17:22: missed: not vectorized: complicated access pattern.\n",
            "mm.c:14:17: missed: couldn't vectorize loop\n",
            "mm.c:16:22: missed: not vectorized: complicated access pattern.\n",
            "mm.c:18:22: missed: statement clobbers memory: __builtin_memset (&matrix_c, 0, 4194304);\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __builtin_putchar (10);\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrusfxT9p3kw"
      },
      "source": [
        "O parâmetro ***-fopt-info-vec-note***, por sua vez, mostra detalhes sobre os *loops* e as otimizações realizadas.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "039uHkDcn7nu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0350d780-7d43-4f33-a65e-8ece1d726e7f"
      },
      "source": [
        "# -fopt-info-vec-note: Detailed info about all loops and optimizations being done.\n",
        "! gcc mm.c -o mm -O3 -fopt-info-vec-note"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm.c:10:5: note: vectorized 3 loops in function.\n",
            "mm.c:26:15: note: ***** Analysis failed with vector mode V4SF\n",
            "mm.c:26:15: note: ***** Skipping vector mode V16QI, which would repeat the analysis for V4SF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5BwfB2yqVS4"
      },
      "source": [
        "***-fopt-info-vec-all*** exibe todas informações mostradas pelos parâmetros anteriores.\n",
        "\n",
        "Prepare-se!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmyOw5_5qRGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3961fe-aba4-4029-c69e-bff732090329"
      },
      "source": [
        "# -fopt-info-vec-all: All previous options together.\n",
        "! gcc mm.c -o mm -O3 -fopt-info-vec-all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm.c:26:15: missed: couldn't vectorize loop\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "mm.c:27:17: missed: couldn't vectorize loop\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "mm.c:21:15: missed: couldn't vectorize loop\n",
            "mm.c:21:15: missed: not vectorized: multiple nested loops.\n",
            "mm.c:22:17: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:23:19: missed: couldn't vectorize loop\n",
            "mm.c:23:19: missed: outer-loop already vectorized.\n",
            "mm.c:14:17: missed: couldn't vectorize loop\n",
            "mm.c:17:22: missed: not vectorized: complicated access pattern.\n",
            "mm.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:14:17: missed: couldn't vectorize loop\n",
            "mm.c:16:22: missed: not vectorized: complicated access pattern.\n",
            "mm.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:10:5: note: vectorized 3 loops in function.\n",
            "mm.c:18:22: missed: statement clobbers memory: __builtin_memset (&matrix_c, 0, 4194304);\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __builtin_putchar (10);\n",
            "mm.c:26:15: note: ***** Analysis failed with vector mode V4SF\n",
            "mm.c:26:15: note: ***** Skipping vector mode V16QI, which would repeat the analysis for V4SF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtd45aZqmA3B"
      },
      "source": [
        "## Otimizações de autovetorização GCC\n",
        "\n",
        "[GCC Autovectorization flags](https://www.codingame.com/playgrounds/283/sse-avx-vectorization/autovectorization)\n",
        "\n",
        "    GCC is an advanced compiler, and with the optimization flags -O3 or -ftree-vectorize\n",
        "    the compiler will search for loop vectorizations (remember to specify the -mavx flag too).\n",
        "    The source code remains the same, but the compiled code by GCC is completely different.\n",
        "\n",
        "    GCC won't log anything about automatic vectorization unless some flags are enabled.\n",
        "    If you need details of autovectorization results you can use the compiler flags:\n",
        "\n",
        "    -fopt-info-vec or -fopt-info-vec-optimized: The compiler will log which loops (by line N°) are being vector optimized.\n",
        "    -fopt-info-vec-missed: Detailed info about loops not being vectorized, and a lot of other detailed information.\n",
        "    -fopt-info-vec-note: Detailed info about all loops and optimizations being done.\n",
        "    -fopt-info-vec-all: All previous options together.\n",
        "\n",
        "    NOTE: There are similar -fopt-info-[options]-optimized flags for other compiler optimizations,\n",
        "    like inline: -fopt-info-inline-optimized\n",
        "\n",
        "\n",
        "## Mais sobre otimizações do gcc\n",
        "\n",
        "https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_ZxatKW-RcB"
      },
      "source": [
        "# Trabalhando com a matriz transposta e acessos contíguos\n",
        "\n",
        "Considerando o acesso não contíguo aos dados da matriz B, percorrida em suas colunas, seria de se esperar que o compilador não conseguisse fazer a vetorização do *loop* interno da multiplicação tradicional (for i... for j... for k...)\n",
        "\n",
        "Examinando os logs do compilador, contudo, vê-se que houve alguma vetorização deste *loop*.\n",
        "\n",
        "Para testar o efeito do acesso contíguo também aos dados da matriz B, uma nova versão do código da multiplicação é apresentada a seguir.\n",
        "\n",
        "Considerando matrizes quadradas, a geração da versão transposta geraria a troca dos elementos B[i][j] por B[j][i]. Supondo que essa troca foi feita, ou que a matriz B já é uma versão transposta, a única mudança no código é o modo em que os elementos da matriz B são percorridos nas operações de multiplicação e soma para cálculo de cada elemento de C.\n",
        "\n",
        "Tendo a matriz B na forma transposta, é possível ajustar o laço interno de cálculo dos elementos da matriz C para que os acessos aos elementos ocorram de forma contígua, como segue:\n",
        "\n",
        "```\n",
        "result[i][j] += matrix_a[i][k] * matrix_b[j][k];\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "    [https://blog.qiqitori.com/2018/05/matrix-multiplication-using-gccs-auto-vectorization/]\n",
        "\n",
        "    As you can see, when we access matrix_a, we access matrix_a[i][0], then matrix_a[i][1], matrix_a[i][2], matrix_a[i][3], and so on until we have hit the end. This is nice and sequential memory access, and is much faster than haphazard (“random”) accesses.\n",
        "\n",
        "    In matrix_b, we have somewhat haphazard accesses. The first access is matrix_b[0][j], the second access is (in our example) 1024 bytes away from the first, matrix_b[1][j], then another 1024 bytes away at matrix_b[2][j], etc. There is a 1024 byte gap between every access. This kind of access is slow. It ruins the CPU’s caching system.\n",
        "\n",
        "    This is why matrix_b will often be transposed in matrix multiplication code. If you transpose the matrix, the rows will be the columns and the columns the rows, thus you get nice and sequential access to matrix_b. (In our demonstration code, we are using square matrices with the same values everywhere, so we don’t actually have to do any copying work, as matrix_b is the same transposed or not. So all we have to do is swap the indices.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BqA_7m4G5A5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ba55d8-b38b-42d7-a7c0-3facc07d8d3f"
      },
      "source": [
        "%%writefile mmT.c\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "float matrix_a[1024][1024];\n",
        "float matrix_b[1024][1024];\n",
        "float result_matrix[1024][1024];\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  int i,j,k;\n",
        "\n",
        "  for (i = 0; i < 1024; i++) {        // inicia matrizes\n",
        "    for (j = 0; j < 1024; j++) {\n",
        "      matrix_a[i][j] = 0.1f;\n",
        "      matrix_b[i][j] = 0.2f;\n",
        "      result_matrix[i][j] = 0.0f;     // pode ser substituído por memset (0...)\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (i = 0; i < 1024; i++) {     // iterate over rows of matrix A/result matrix\n",
        "    for (j = 0; j < 1024; j++) {   // iterate over columns matrix B/result matrix\n",
        "      for (k = 0; k < 1024; k++) { // iterate over colums of matrix A and COLUMNS of matrix BT\n",
        "        result_matrix[i][j] += matrix_a[i][k] * matrix_b[j][k];\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (i = 0; i < 1024; i++) {\n",
        "    for (j = 0; j < 1024; j++) {\n",
        "      printf(\"%f \", result_matrix[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        " }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mmT.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUqD7MWKHvyN"
      },
      "source": [
        "Pensemos na vetorização, supondo que o compilador vai vetorizar o *loop*, agora tendo tanto os dados a serem manipulados das linhas da matriz A e das colunas da matriz (transposta, agora nas linhas de B) armazenados de forma contígua na memória.\n",
        "\n",
        "Para tanto, é possível usar parâmetros de otimização do compilador:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvhnvD0V-9wF",
        "outputId": "758fa1e8-6b05-4c7d-f52f-352356e4680a"
      },
      "source": [
        "# -ftree-vectorize is a simple alias to -ftree-loop-vectorize + -ftree-slp-vectorize\n",
        "! gcc -O3 mmT.c -o mmT -fopt-info-optall-optimized -ftree-vectorize -ftree-vectorizer-verbose=5\n",
        "! time ./mmT > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mmT.c:32:5: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mmT.c:30:7: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mmT.c:12:17: optimized: Loop nest 1 distributed: split to 2 loops and 1 library calls.\n",
            "mmT.c:22:21: optimized: loop vectorized using 16 byte vectors\n",
            "mmT.c:13:19: optimized: loop vectorized using 16 byte vectors\n",
            "mmT.c:13:19: optimized: loop vectorized using 16 byte vectors\n",
            "\n",
            "real\t0m2.206s\n",
            "user\t0m2.172s\n",
            "sys\t0m0.013s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Z_Jwd0VmryN"
      },
      "source": [
        "Novamente, o parâmetro ***-fopt-info-vec-note*** mostra detalhes sobre os *loops* e as otimizações realizadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaC-9KSEnDT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92951433-5c42-41ee-9250-98b66fc6d3aa"
      },
      "source": [
        "# -fopt-info-vec-note: Detailed info about all loops and optimizations being done.\n",
        "! gcc mmT.c -o mmT -O3 -fopt-info-vec-note"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mmT.c:8:5: note: vectorized 3 loops in function.\n",
            "mmT.c:28:17: note: ***** Analysis failed with vector mode V4SF\n",
            "mmT.c:28:17: note: ***** Skipping vector mode V16QI, which would repeat the analysis for V4SF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10g-OnGWnoLi"
      },
      "source": [
        "O parâmetro ***-fopt-info-vec-missed*** indica as oportunidades buscadas mas que não puderam ser exploradas, associadas aos motivos encontrados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g37q_GBmno25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158a4f58-fc53-4155-93dc-394e099dfab1"
      },
      "source": [
        "# -fopt-info-vec-missed: Detailed info about loops not being vectorized, and a lot of other detailed information.\n",
        "! gcc mmT.c -o mmT -O3 -fopt-info-vec-missed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mmT.c:28:17: missed: couldn't vectorize loop\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "mmT.c:29:19: missed: couldn't vectorize loop\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "mmT.c:20:17: missed: couldn't vectorize loop\n",
            "mmT.c:20:17: missed: not vectorized: multiple nested loops.\n",
            "mmT.c:21:19: missed: couldn't vectorize loop\n",
            "mmT.c:23:60: missed: not vectorized: complicated access pattern.\n",
            "mmT.c:12:17: missed: couldn't vectorize loop\n",
            "mmT.c:15:22: missed: not vectorized: complicated access pattern.\n",
            "mmT.c:12:17: missed: couldn't vectorize loop\n",
            "mmT.c:14:22: missed: not vectorized: complicated access pattern.\n",
            "mmT.c:16:27: missed: statement clobbers memory: __builtin_memset (&result_matrix, 0, 4194304);\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _7);\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __builtin_putchar (10);\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aparentemente, o loop interno da multiplicação não foi vetorizado."
      ],
      "metadata": {
        "id": "djq45PIdDBzM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ0MJm2VoZfe"
      },
      "source": [
        "# Outras otimizações\n",
        "\n",
        "Os 2 blocos de execução a seguir ilustram chamadas de compilação em que são feitas referências explícitas às extensões de vetorização SSE e AVX.\n",
        "\n",
        "Uma diferença entre essas extensões é que AVX tem registradores de 256 bits, o que permite que mais operações sejam realizadas em paralelo, o dobro do que é oferecido pelos registradores de 128 bits de SSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z87EpOjC-824",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ada8c9-9db4-49d9-96d4-d758b313a6a5"
      },
      "source": [
        "# -O3, SSE auto-vectorization, straight\n",
        "! gcc -O3 -fopt-info-optall-optimized -ftree-vectorize -msse -o mm mm.c\n",
        "! time ./mm > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm.c:29:5: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mm.c:28:7: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mm.c:14:17: optimized: Loop nest 1 distributed: split to 2 loops and 1 library calls.\n",
            "mm.c:22:17: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "mm.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "\n",
            "real\t0m1.819s\n",
            "user\t0m1.767s\n",
            "sys\t0m0.011s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No bloco a seguir, solicita-se ao compilador que utilize explicitamente as extensões AVX."
      ],
      "metadata": {
        "id": "AcZJFeFhDgWa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB2vDmUh_Ify",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d2720e-d41a-43c6-952c-484c5f4c5cd8"
      },
      "source": [
        "# -O3, AVX auto-vectorization, straight\n",
        "! gcc -O3 -fopt-info-optall-optimized -ftree-vectorize -mavx -o mm mm.c\n",
        "! time ./mm > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm.c:29:5: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mm.c:28:7: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mm.c:14:17: optimized: Loop nest 1 distributed: split to 2 loops and 1 library calls.\n",
            "mm.c:22:17: optimized: loop vectorized using 32 byte vectors\n",
            "mm.c:15:19: optimized: loop vectorized using 32 byte vectors\n",
            "mm.c:15:19: optimized: loop vectorized using 32 byte vectors\n",
            "\n",
            "real\t0m1.084s\n",
            "user\t0m1.062s\n",
            "sys\t0m0.011s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuehu7BDJgNu"
      },
      "source": [
        "# Usando vetorização e OpenMP\n",
        "\n",
        "Para esse problema, é claro que também podemos usar OpenMP, por exemplo, para paralelizar o código usando diversas *threads*.\n",
        "\n",
        "Para gerar mais carga, as multiplicações agora envolverão matrizes maiores (2048x2048)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36_gG5n9w48Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3c5d99-7277-4b91-fd18-687fa61fa174"
      },
      "source": [
        "%%writefile mmomp.c\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define DIM 2048\n",
        "\n",
        "float matrix_a[DIM][DIM];\n",
        "float matrix_b[DIM][DIM];\n",
        "float matrix_c[DIM][DIM];\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  int i,j,k;\n",
        "\n",
        "  #pragma omp parallel for private(j)\n",
        "  for (i = 0; i < DIM; i++) {           // inicia matrizes\n",
        "    for (j = 0; j < DIM; j++) {\n",
        "      matrix_a[i][j] = 0.1f;\n",
        "      matrix_b[i][j] = 0.2f;\n",
        "      matrix_c[i][j] = 0.0f;       // pode ser substituído por memset (0...)\n",
        "    }\n",
        "  }\n",
        "\n",
        "  #pragma omp parallel for private(j,k)\n",
        "  for (i = 0; i < DIM; i++)          // iterate over rows of matrix A/result matrix\n",
        "    for (j = 0; j < DIM; j++)        // iterate over columns matrix B/result matrix\n",
        "      for (k = 0; k < DIM; k++)      // iterate over columns of matrix A and rows of matrix B\n",
        "        matrix_c[i][j] += matrix_a[i][k]*matrix_b[k][j];\n",
        "\n",
        "  for (i = 0; i < DIM; i++) {\n",
        "    for (j = 0; j < DIM; j++)\n",
        "      printf(\"%f \", matrix_c[i][j]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        " }"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mmomp.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOnMpJjSxG_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4a5b00-10a2-4829-e9e8-92c849fc8a6f"
      },
      "source": [
        "! gcc -Wall -O3 mmomp.c -o mmomp -fopt-info-optall-optimized -ftree-vectorize\n",
        "! time ./mmomp > /dev/null\n",
        "! echo; echo \"Agora com OpenMP:\"; echo\n",
        "! gcc -Wall -O3 mmomp.c -o mmomp -fopt-info-optall-optimized -ftree-vectorize -fopenmp\n",
        "! echo; echo 2 threads:\n",
        "! export OMP_NUM_THREADS=2 && time ./mmomp > /dev/null\n",
        "! echo; echo 4 threads:\n",
        "! export OMP_NUM_THREADS=4 && time ./mmomp > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[Kmmomp.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmain\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kmmomp.c:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring ‘\u001b[01m\u001b[K#pragma omp parallel\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunknown-pragmas\u0007-Wunknown-pragmas\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   14 |   #pragma omp parallel for private(j)\n",
            "      | \n",
            "\u001b[01m\u001b[Kmmomp.c:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring ‘\u001b[01m\u001b[K#pragma omp parallel\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunknown-pragmas\u0007-Wunknown-pragmas\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   23 |   #pragma omp parallel for private(j,k)\n",
            "      | \n",
            "mmomp.c:32:5: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mmomp.c:31:7: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mmomp.c:15:17: optimized: Loop nest 1 distributed: split to 2 loops and 1 library calls.\n",
            "mmomp.c:25:19: optimized: loop vectorized using 16 byte vectors\n",
            "mmomp.c:16:19: optimized: loop vectorized using 16 byte vectors\n",
            "mmomp.c:16:19: optimized: loop vectorized using 16 byte vectors\n",
            "\n",
            "real\t0m26.374s\n",
            "user\t0m25.911s\n",
            "sys\t0m0.045s\n",
            "\n",
            "Agora com OpenMP:\n",
            "\n",
            "mmomp.c:32:5: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mmomp.c:31:7: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "mmomp.c:25:19: optimized: loop vectorized using 16 byte vectors\n",
            "mmomp.c:14:11: optimized: Loop nest 1 distributed: split to 2 loops and 1 library calls.\n",
            "mmomp.c:16:19: optimized: loop vectorized using 16 byte vectors\n",
            "mmomp.c:16:19: optimized: loop vectorized using 16 byte vectors\n",
            "\n",
            "2 threads:\n",
            "\n",
            "real\t0m27.301s\n",
            "user\t0m46.032s\n",
            "sys\t0m0.066s\n",
            "\n",
            "4 threads:\n",
            "\n",
            "real\t0m27.263s\n",
            "user\t0m46.214s\n",
            "sys\t0m0.067s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Operações SIMD com OpenMP\n",
        "\n",
        "Uma outra construção específica de OpenMP é a diretiva [SIMD](https://www.openmp.org/spec-html/5.0/openmpsu42.html), que indica ao compilador que o loop a seguir pode ser executado usando instruções SIMD do processador.\n",
        "\n",
        "```\n",
        "#pragma omp simd [clause[ [,] clause] ... ] new-line\n",
        "   for-loops\n",
        "```\n",
        "\n",
        "Esta diretiva pode ser declarada em qualquer trecho do código, acima de *for loops* que venham a ser encontrados pelas ***tasks***.\n",
        "\n",
        "\n",
        "***Obs***: pelo que testei, contudo, o código gerado não explorou instruções SIMD do processador, salvo se os parâmetros -O2 ou -O3 fossem utilizados também.\n",
        "Neste caso, o código SIMD gerado foi o mesmo que sem utilizar a diretiva ***omp simd*** :-("
      ],
      "metadata": {
        "id": "ggbpSc3cNjaX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpLxXWsr6eCm"
      },
      "source": [
        "# MM usando armazenamento contíguo\n",
        "\n",
        "O exemplo a seguir procura explorar o armazenamento de matrizes como ponteiros. Para tanto, supõe que a matriz está armazenada como uma sequência de linhas.\n",
        "\n",
        "Uma restrição deste tipo de armazenamento é que, ao tratar as operações com as matrizes (ponteiros), o compilador não tem certeza se os dados apontados por este ponteiro não são acessados por outras referências (*aliases*) . Deste modo, operações de vetorização, por exemplo, podem não ser feitas, por motivo de segurança.\n",
        "\n",
        "\n",
        "Para tentar evitar que a vetorização deixe de ocorrer, uma opção é usar o qualificador \\_\\_restrict__.\n",
        "\n",
        "```\n",
        "The restrict keyword may be used to assert that the memory referenced by a pointer is\n",
        "not aliased, i.e. that it is not accessed in any other way.\n",
        "```\n",
        "\n",
        "\n",
        "https://en.wikipedia.org/wiki/Restrict\n",
        "\n",
        "```\n",
        "In the C programming language, restrict is a keyword, introduced by the C99 standard,\n",
        "that can be used in pointer declarations.\n",
        "By adding this type qualifier, a programmer hints to the compiler that for the lifetime of the\n",
        "pointer, no other pointer will be used to access the object to which it points.\n",
        "This allows the compiler to make optimizations (for example, vectorization) that would not\n",
        "otherwise have been possible.\n",
        "\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "https://gcc.gnu.org/onlinedocs/gcc/Loop-Specific-Pragmas.html\n",
        "\n",
        "Loop-Specific Pragmas\n",
        "\n",
        "\\#pragma GCC ivdep\n",
        "\n",
        "    With this pragma, the programmer asserts that there are no loop-carried\n",
        "    dependencies which would prevent consecutive iterations of the following\n",
        "    loop from executing concurrently with SIMD (single instruction multiple\n",
        "    data) instructions.\n",
        "\n",
        "    For example, the compiler can only unconditionally vectorize the following loop with the pragma:\n",
        "\n",
        "    void foo (int n, int *a, int *b, int *c)\n",
        "    {\n",
        "      int i, j;\n",
        "    #pragma GCC ivdep\n",
        "      for (i = 0; i < n; ++i)\n",
        "        a[i] = b[i] + c[i];\n",
        "    }\n",
        "\n",
        "    In this example, using the restrict qualifier had the same effect.\n",
        "    In the following example, that would not be possible. Assume k < -m or k >= m.\n",
        "    Only with the pragma, the compiler knows that it can unconditionally vectorize the following loop:\n",
        "\n",
        "    void ignore_vec_dep (int *a, int k, int c, int m)\n",
        "    {\n",
        "    #pragma GCC ivdep\n",
        "      for (int i = 0; i < m; i++)\n",
        "        a[i] = a[i + k] * c;\n",
        "    }\n",
        "\n",
        "\\#pragma GCC unroll n\n",
        "\n",
        "    You can use this pragma to control how many times a loop should be unrolled.\n",
        "    It must be placed immediately before a for, while or do loop or a #pragma GCC ivdep,\n",
        "    and applies only to the loop that follows. n is an integer constant expression\n",
        "    specifying the unrolling factor. The values of 0 and 1 block any unrolling of the loop.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFO4Zeo26YCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b39c60-9295-4670-f616-9b8c7b69a111"
      },
      "source": [
        "%%writefile mm2.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define TAM 1024\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "  int i,j,k;\n",
        "\n",
        "//  float *__restrict__ matrix_a = malloc(TAM*TAM*sizeof(float));\n",
        "//  float *__restrict__ matrix_b = malloc(TAM*TAM*sizeof(float));\n",
        "//  float *__restrict__ matrix_c = malloc(TAM*TAM*sizeof(float));\n",
        "\n",
        "  float * matrix_a = malloc(TAM*TAM*sizeof(float));\n",
        "  float * matrix_b = malloc(TAM*TAM*sizeof(float));\n",
        "  float * matrix_c = malloc(TAM*TAM*sizeof(float));\n",
        "\n",
        "  for (i = 0; i < TAM * TAM; i++) {\n",
        "    *(matrix_a +i) = 0.1f;\n",
        "    *(matrix_b +i) = 0.2f;\n",
        "    *(matrix_c +i) = 0.0f;\n",
        "  }\n",
        "\n",
        "  #pragma GCC ivdep\n",
        "  for (i = 0; i < 1024; i++)\n",
        "    for (j = 0; j < 1024; j++)\n",
        "      for (k = 0; k < 1024; k++)\n",
        "        matrix_c[i*1024+j] += matrix_a[i*1024 +k] * matrix_b[k*1024 +j];\n",
        "\n",
        "  for (int i = 0; i < TAM; i++) {\n",
        "    for (int j = 0; j < TAM; j++)\n",
        "      printf(\"%f \", matrix_c[i*TAM+j]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm2.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2ohwiRI73xN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a841b7b9-95e9-43bc-abe7-f8c5808d338c"
      },
      "source": [
        "# ! gcc --version\n",
        "#\n",
        "! gcc -Wall -g -O3 mm2.c -o mm2 -ftree-vectorize -fopt-info-optall-optimized\n",
        "#\n",
        "! echo\n",
        "# -fopt-info-vec-missed: Detailed info about loops not being vectorized, and a lot of other detailed information.\n",
        "! gcc mm2.c -o mm2 -O3 -fopt-info-vec-missed\n",
        "#\n",
        "# -fopt-info-vec-note: Detailed info about all loops and optimizations being done.\n",
        "# ! gcc mm2.c -o mm2 -O3 -fopt-info-vec-note\n",
        "# ! gcc mm2.c -o mm2 -O3\n",
        "# ! time ./mm2 > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mm2.c:35:5: optimized:   Inlining printf/15 into main/39 (always_inline).\n",
            "mm2.c:34:7: optimized:   Inlining printf/15 into main/39 (always_inline).\n",
            "mm2.c:20:17: optimized: Loop 1 distributed: split to 2 loops and 1 library calls.\n",
            "mm2.c:28:19: optimized: loop vectorized using 16 byte vectors\n",
            "mm2.c:20:17: optimized: loop vectorized using 16 byte vectors\n",
            "mm2.c:20:17: optimized: loop vectorized using 16 byte vectors\n",
            "\n",
            "mm2.c:32:21: missed: couldn't vectorize loop\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _31);\n",
            "mm2.c:33:23: missed: couldn't vectorize loop\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _31);\n",
            "mm2.c:27:3: missed: couldn't vectorize loop\n",
            "mm2.c:27:3: missed: not vectorized: multiple nested loops.\n",
            "mm2.c:29:21: missed: couldn't vectorize loop\n",
            "mm2.c:29:21: missed: outer-loop already vectorized.\n",
            "mm2.c:16:22: missed: statement clobbers memory: matrix_a_46 = malloc (4194304);\n",
            "mm2.c:17:22: missed: statement clobbers memory: matrix_b_48 = malloc (4194304);\n",
            "mm2.c:18:22: missed: statement clobbers memory: matrix_c_50 = malloc (4194304);\n",
            "mm2.c:23:20: missed: statement clobbers memory: __builtin_memset (matrix_c_50, 0, 4194304);\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __printf_chk (1, \"%f \", _31);\n",
            "/usr/include/x86_64-linux-gnu/bits/stdio2.h:112:10: missed: statement clobbers memory: __builtin_putchar (10);\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqGX10kKJPZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f323a9-5ea1-4eee-a949-478fda061709"
      },
      "source": [
        "# ! if $( ! apt list gdb | grep \"installed\" &> /dev/null ) ; then apt install -y gdb ; fi\n",
        "! if [ ! mm2 -nt mm2.c ]; then gcc -Wall mm2.c -o mm2 -g -O3 -fopt-info-optall-optimized -ftree-vectorize ; fi\n",
        "# ! gdb ./mm2 -ex \"break 28\" -ex \"r\"\n",
        "! time ./mm2 > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t0m1.520s\n",
            "user\t0m1.493s\n",
            "sys\t0m0.015s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8czZVED5X7R"
      },
      "source": [
        "# Teste de linearização das matrizes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcX1ohXZ5arf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191a6fc8-8436-44f1-c11e-6cf170dd7c95"
      },
      "source": [
        "%%writefile mm-sl.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define TAM 1024\n",
        "// #define TAM 2048\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "  int i,j,k;\n",
        "\n",
        "  float *matrix_a = malloc(TAM*TAM*sizeof(float));\n",
        "  float *matrix_b = malloc(TAM*TAM*sizeof(float));\n",
        "  float *result_matrix = malloc(TAM*TAM*sizeof(float));\n",
        "\n",
        "  for (i = 0; i < TAM * TAM; i++) {\n",
        "    *(matrix_a +i) = 0.1f;\n",
        "    *(matrix_b +i) = 0.2f;\n",
        "    // *(result_matrix +i) = 0.0f;\n",
        "  }\n",
        "\n",
        "  for (i = 0; i < TAM; i++) {     // iterate over rows of matrix A/result matrix\n",
        "    for (j = 0; j < TAM; j++) {   // iterate over columns matrix B/result matrix\n",
        "      result_matrix[i*TAM+j] = 0.0;\n",
        "      for (k = 0; k < TAM; k++) { // iterate over columns of matrix A and rows of matrix B\n",
        "        result_matrix[i*TAM+j] += matrix_a[i*TAM +k] * matrix_b[j*TAM +k];\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < TAM; i++) {\n",
        "    for (int j = 0; j < TAM; j++)\n",
        "      printf(\"%f \", result_matrix[i*TAM+j]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm-sl.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7JbLjqC5jsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e69f6a84-c370-475b-aa29-e0dcfa2d2f71"
      },
      "source": [
        "%%writefile mm-loc.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define TAM 1024\n",
        "// #define TAM 2048\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "  int i,j,k;\n",
        "  float aux;\n",
        "\n",
        "  float *matrix_a = malloc(TAM*TAM*sizeof(float));\n",
        "  float *matrix_b = malloc(TAM*TAM*sizeof(float));\n",
        "  float *result_matrix = malloc(TAM*TAM*sizeof(float));\n",
        "\n",
        "  for (i = 0; i < TAM * TAM; i++) {\n",
        "    *(matrix_a +i) = 0.1f;\n",
        "    *(matrix_b +i) = 0.2f;\n",
        "    // *(result_matrix +i) = 0.0f;\n",
        "  }\n",
        "\n",
        "  for (i = 0; i < TAM; i++) { // iterate over rows of matrix A/result matrix\n",
        "    for (j = 0; j < TAM; j++) { // iterate over columns matrix B/result matrix\n",
        "      aux = 0.0;\n",
        "      for (k = 0; k < TAM; k++) { // iterate over columns of matrix A and rows of matrix B\n",
        "        // result_matrix[i*TAM+j] += matrix_a[i*TAM +k] * matrix_b[j*TAM +k];\n",
        "        aux += matrix_a[i*TAM +k] * matrix_b[j*TAM +k];\n",
        "      }\n",
        "      result_matrix[i*TAM+j] = aux;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < TAM; i++) {\n",
        "    for (int j = 0; j < TAM; j++)\n",
        "      printf(\"%f \", result_matrix[i*TAM+j]);\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mm-loc.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGfHsWT16Lxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a02e05c-69ae-406d-b3cb-422b0c29e9e1"
      },
      "source": [
        "! if [ ! mm-sl -nt mm-sl.c ]; then gcc -Wall mm-sl.c -o mm-sl -O3; fi\n",
        "! if [ ! mm-loc -nt mm-loc.c ]; then gcc -Wall mm-loc.c -o mm-loc -O3; fi\n",
        "! time ./mm-sl > /dev/null\n",
        "! time ./mm-loc > /dev/null"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "real\t0m2.185s\n",
            "user\t0m2.156s\n",
            "sys\t0m0.012s\n",
            "\n",
            "real\t0m2.727s\n",
            "user\t0m2.636s\n",
            "sys\t0m0.015s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se vê, o desempenho com o uso de uma variável local, neste caso, com -O2 ou -O3, deixa de usar a possibilidade de somas parciais também vetorizadas no salvamento dos valores parciais nas linhas da matriz C.\n",
        "\n",
        "Sem as otimizações de vetorização, o uso de variável parcial vale a pena, explorando a localidade e o uso do cache."
      ],
      "metadata": {
        "id": "DmGdeIu4y8Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mm ijk -> ikj\n",
        "\n",
        "Por fim, já que estamos investigando otimizações na multiplicação de matrizes, que tal analisar também a ordem dos *loops* da multiplicação?\n",
        "\n",
        "<br>\n",
        "\n",
        "Será que a inversão dos *loops* intermediário e central tem algum efeito no tempo de execução da multiplicação de matrizes?\n",
        "\n",
        "O que muda nos cálculos?\n",
        "\n",
        "Com esta inversão, percorre-se cada elemento da linha de A, multiplicando-o pelo primeiro elemento das linhas de B, e acumulando este resultado parcial em cada elemento das colunas desta linha de C.\n",
        "\n",
        "Para entender melhor os cálculos com valores parciais, veja: https://commons.wikimedia.org/wiki/Category:Animations_of_optimization_(image_set_by_Maxiantor).\n",
        "\n",
        "<br>\n",
        "\n",
        "Em suma, há um reúso máximo do valor de cada elemento das linhas de A, aproveitando também o cache na busca dos elementos da linha de B.\n",
        "\n",
        "A questão é apenas se as somas parciais podem ser feitas em paralelo...\n",
        "\n",
        "Será que ***#pragma omp [atomic](https://www.openmp.org/spec-html/5.1/openmpsu105.html#x138-1480002.19.7) update*** resolve?"
      ],
      "metadata": {
        "id": "41FfbdrVrjZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ikj.c\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define TAM 1024\n",
        "\n",
        "float matrix_a[TAM][TAM];\n",
        "float matrix_b[TAM][TAM];\n",
        "float matrix_c[TAM][TAM];\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "  int i,j,k;\n",
        "\n",
        "  for (i = 0; i < TAM; i++) {        // inicia matrizes\n",
        "    for (j = 0; j < TAM; j++) {\n",
        "      matrix_a[i][j] = 0.1f;\n",
        "      matrix_b[i][j] = 0.2f;\n",
        "      matrix_c[i][j] = 0.0f;     // pode ser substituído por memset (0...)\n",
        "    }\n",
        "  }\n",
        "\n",
        "  for (i = 0; i < TAM; i++)      // percorre as linhas de C\n",
        "      for (k = 0; k < TAM; k++)  // percorre colunas da linha de A e linhas da coluna de B\n",
        "    for (j = 0; j < TAM; j++)    // percorre colunas de C\n",
        "        matrix_c[i][j] += matrix_a[i][k] * matrix_b[k][j];\n",
        "\n",
        "\n",
        "  for (i = 0; i < TAM; i++) {\n",
        "    for (j = 0; j < TAM; j++) {\n",
        "      printf(\"%f \", matrix_c[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        " }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxB958Qlrm_h",
        "outputId": "c7a1f814-3085-4b65-da08-1a4bd826d57f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ikj.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gcc -Wall ikj.c -o ikj -O3 -ftree-vectorize -fopt-info-optall-optimized # -fopt-info-optall-missed\n",
        "! time ./ikj > /dev/null\n",
        "! echo\n",
        "! gcc -Wall ikj.c -o ikj-avx -O3 -mavx -fopt-info-optall-optimized\n",
        "! time ./ikj-avx > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BgjM9o1sxsB",
        "outputId": "839b0190-2e32-48fe-f9c6-9b7d4853141f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ikj.c:32:5: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "ikj.c:30:7: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "ikj.c:23:21: optimized: applying unroll and jam with factor 2\n",
            "ikj.c:14:17: optimized: Loop nest 1 distributed: split to 2 loops and 1 library calls.\n",
            "ikj.c:24:19: optimized: loop vectorized using 16 byte vectors\n",
            "ikj.c:24:19: optimized: loop vectorized using 16 byte vectors\n",
            "ikj.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "ikj.c:15:19: optimized: loop vectorized using 16 byte vectors\n",
            "\n",
            "real\t0m1.388s\n",
            "user\t0m1.327s\n",
            "sys\t0m0.012s\n",
            "\n",
            "ikj.c:32:5: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "ikj.c:30:7: optimized:   Inlining printf/15 into main/26 (always_inline).\n",
            "ikj.c:23:21: optimized: applying unroll and jam with factor 2\n",
            "ikj.c:14:17: optimized: Loop nest 1 distributed: split to 2 loops and 1 library calls.\n",
            "ikj.c:24:19: optimized: loop vectorized using 32 byte vectors\n",
            "ikj.c:24:19: optimized: loop vectorized using 32 byte vectors\n",
            "ikj.c:15:19: optimized: loop vectorized using 32 byte vectors\n",
            "ikj.c:15:19: optimized: loop vectorized using 32 byte vectors\n",
            "\n",
            "real\t0m0.785s\n",
            "user\t0m0.768s\n",
            "sys\t0m0.009s\n"
          ]
        }
      ]
    }
  ]
}