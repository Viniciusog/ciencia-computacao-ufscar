{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yKPYxczUHWhp",
        "jG2GURIPkhib",
        "KVnvyTi3lbsi"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKPYxczUHWhp"
      },
      "source": [
        "# PPD: OpenMP - *Worksharing*\n",
        "\n",
        "Hélio - DC/UFSCar - 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG2GURIPkhib"
      },
      "source": [
        "# Paralelismo com divisão de trabalho: *worksharing*\n",
        "\n",
        "Além de permitir a **replicação** da execução de trechos de código, OpenMP possui construções para **dividir** as execuções desses trechos. Essas construções são chamadas *worksharing* e sempre se aplicam dentro de uma região paralela definida pela diretiva ***parallel***.\n",
        "\n",
        "Construções do tipo *worksharing* **não** geram novas *threads*, mas se aplicam às *threads* do time associado à região paralela atual.\n",
        "\n",
        "Não há uma barreira no início de uma construção desse tipo, mas uma é inserida automaticamente ao seu final.\n",
        "\n",
        "Tipos de construções para divisão de carga (*worksharing*) (para linguagem C):\n",
        "\n",
        "* **for** : dividem as iterações de um *loop* entre as *threads* do time. Representam o paralelismo de dados.\n",
        "* **sections** : dividem o trabalho em regiões explicitamente definidas. Cada seção é executada por uma *thread*. Pode ser usada para representar o paralelismo funcional.\n",
        "* **single** : serializa um trecho de código, que é executado por apenas 1 *thread* do time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVnvyTi3lbsi"
      },
      "source": [
        "# *Single*: executando um trecho de código por apenas uma *thread*\n",
        "\n",
        "Aplicada dentro de uma região paralela, a diretiva **single** especifica que o código associado deve ser executado por apenas uma *thread* no time. Fica a critério da API determinar qual será, não sendo necessariamente a *master*.\n",
        "\n",
        "Normalmente, o uso da diretiva *single* é útil no tratamento de seções de código que não são *thread safe* (como E/S) e devem ser executadas por uma *thread* apenas.\n",
        "\n",
        "```\n",
        "#pragma omp parallel\n",
        "{\n",
        "  ...\n",
        "  #pragma omp single [clause ...]  newline\n",
        "    structured_block\n",
        "  ...\n",
        "}\n",
        "```\n",
        "```\n",
        "cláusulas:  private (list)\n",
        "            firstprivate (list)\n",
        "            nowait\n",
        "```\n",
        "*Theads* no time que não executam a diretiva *single* esperam no final do código associado, exceto se a cláusula *nowait* for especificada.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_SaF5USlIMF",
        "outputId": "66b210ea-040f-4f64-d89a-d84cab99f926"
      },
      "source": [
        "%%writefile s1.c\n",
        "\n",
        "#include <stdio.h>    // para printf()\n",
        "#include <stdlib.h>   // para random()\n",
        "#include <omp.h>      // para omp_get_thread_num()\n",
        "\n",
        "int\n",
        "main()\n",
        "{\n",
        "   int a, i;\n",
        "   // ...\n",
        "\n",
        "// @helio: todo: trocar o exemplo com rand...\n",
        "\n",
        "#pragma omp parallel shared(a) private(i)\n",
        "{\n",
        "   // ...                     // Todas as threads do time executam essa parte\n",
        "  #pragma omp single          // Só uma thread do time vai executar esse bloco\n",
        "  {\n",
        "    printf(\"thread %d executou código no bloco single\\n\\n\", omp_get_thread_num());\n",
        "    srand(time(NULL));\n",
        "  }                           // Uma barreira é usada aqui, se a cláusula nowait não for especificada\n",
        "\n",
        "  // ...                      // restante do código do bloco paralelo: todas as threads executam\n",
        "  printf(\"thread %d executando bloco paralelo\\n\",omp_get_thread_num());\n",
        "  a = rand();\n",
        "  // ...                      // Todas as threads do time executam essa parte\n",
        "} //                          // Fim do bloco paralelo\n",
        "  // ...                      // Só a master thread prossegue\n",
        "\n",
        "  return(0);\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting s1.c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilc2hSLhmNIg"
      },
      "source": [
        "!gcc s1.c -o s1 -fopenmp && ./s1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSxsCSP5ngnu"
      },
      "source": [
        "# *Parallel for*: dividindo as iterações de um *loop*\n",
        "\n",
        "A diretiva *for* especifica que as iterações do *loop* imediatamente abaixo devem ser executadas em paralelo, **dividindo-as** entre as *threads* do time.\n",
        "\n",
        "Emitida dentro de uma região paralela, esta diretiva deve ser sucedida especificamente por um comando **for**.\n",
        "\n",
        "```\n",
        "#pragma omp for [clause ...] newline\n",
        "   Cláusulas:\n",
        "     schedule (type [,chunk])\n",
        "     ordered\n",
        "     private (list)\n",
        "     first private (list)\n",
        "     last private (list)\n",
        "     shared (list)\n",
        "     reduction (operator: list)\n",
        "     collapse (n)\n",
        "     nowait\n",
        "```\n",
        "Cláusulas:\n",
        "\n",
        "* **schedule**: determina como as iterações do *loop* serão divididas entre as *threads* do time.\n",
        "  * ***static***: iterações divididas em blocos de tamanho *chunk*.\n",
        "  * ***dynamic***: iterações divididas em blocos de tamanho *chunk* e alocadas dinamicamente entre as *threads*, à medida que terminam as iterações atribuídas anteriormente.\n",
        "  * ***guided***: número de iterações atribuído em cada rodada é calculado em função das iterações restantes divididas pelo número de *threads*, sendo o resultado decrescido de *chunk*.\n",
        "  * ***runtime***: decisão de atribuição é realizada somente em tempo de execução, usando a política que tiver sido definida pela variável de ambiente OMP_SCHEDULE.\n",
        "  * ***auto***: decisão de atribuição é delegada ao compilador ou software em tempo de execução.\n",
        "* ***nowait***: se usada, esta cláusula indica que *threads* não devem ser sincronizadas no fim do loop paralelo.\n",
        "* ***ordered***: indica que as iterações do loop devem ser executadas em sequência como se fossem trataras em um programa serial.\n",
        "* ***collapse***: indica quantos *loops* em um aninhamento de *loops* (*nested loops*) devem ser agrupados (*collapsed*) em um bloco de iteração maior dividido de acordo com a cláusula *schedule*.\n",
        "\n",
        "\n",
        "**For canônico**\n",
        "\n",
        "Para poder transformar um *loop* sequencial em paralelo é preciso que o compilador OpenMP seja capaz de verificar que o sistema em tempo de execução terá as informações necessárias para determinar o número de iterações ao avaliar a cláusula de controle.\n",
        "\n",
        "Resumidamente, a definição das iterações do comando *for* deve ser clara, para que o suporte em tempo de execução saiba **quantas** e **quais** são as iterações, para poder dividi-las entre as *threads* do time corrente!\n",
        "\n",
        "*For loops* devem possuir a seguinte forma canônica:\n",
        "\n",
        "```\n",
        "for ( index = start; index {<,<=,>=,>} end;\n",
        "     { indx++, ++indx, indx--, --indx, indx+=inc, index-=inc, indx=indx+inc, indx=inc+indx, indx=indx-inc} )\n",
        "```\n",
        "O exemplo a seguir ilustra o uso da diretiva ***for***:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lqLDSefoYrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191f35b1-21ca-423b-82c9-28c7057fef52"
      },
      "source": [
        "%%writefile s2.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <omp.h>\n",
        "\n",
        "#define MAX 20\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "    int i, id, num_it, vet[MAX];\n",
        "\n",
        "    srand(time(NULL));\n",
        "    num_it = rand() % MAX;\n",
        "\n",
        "  #pragma omp parallel num_threads(4) private(id)  // a variável de controle do for precisa ser privada. Isso é feito automaticamente, contudo.\n",
        "  {\n",
        "    // Todas as threads do time executam esse trecho do bloco de código de maneira replicada\n",
        "    id = omp_get_thread_num();\n",
        "\n",
        "    // Construção worksharing (for) divide as iterações entre as threads do time\n",
        "    // Variável de controle do for (i) é feita privada para cada thread, automaticamente!\n",
        "    // Diretiva for deve aparecer dentro de uma região paralela\n",
        "    #pragma omp for         // O único comando permitido na linha abaixo da diretiva for é um for :-)\n",
        "    for (i=0; i < num_it; i++) {\n",
        "        printf(\"Thread %d tratando iteração %d\\n\", id, i);\n",
        "        vet[i] = 2 * i;\n",
        "    }\n",
        "    // todas as threads replicam esse trecho de código, fora do for, mas dentro da região paralela\n",
        "\n",
        "   } // fim da região paralela\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing s2.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtQ6S_p6ocyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e7eb01-3306-4f87-9d24-56b452700cd4"
      },
      "source": [
        "!gcc s2.c -o s2 -fopenmp && ./s2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0 tratando iteração 0\n",
            "Thread 0 tratando iteração 1\n",
            "Thread 0 tratando iteração 2\n",
            "Thread 0 tratando iteração 3\n",
            "Thread 3 tratando iteração 12\n",
            "Thread 2 tratando iteração 8\n",
            "Thread 2 tratando iteração 9\n",
            "Thread 2 tratando iteração 10\n",
            "Thread 2 tratando iteração 11\n",
            "Thread 1 tratando iteração 4\n",
            "Thread 1 tratando iteração 5\n",
            "Thread 1 tratando iteração 6\n",
            "Thread 1 tratando iteração 7\n",
            "Thread 3 tratando iteração 13\n",
            "Thread 3 tratando iteração 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQCvWY6Mogkb"
      },
      "source": [
        "**Forma compacta de declaração do *paralell for***\n",
        "\n",
        "Quando o paralelismo desejado no programa é apenas para divisão das iterações de um comando *for*, é possível usar a declaração compacta da *diretiva for*:\n",
        "\n",
        "```\n",
        "  ...\n",
        "  #pragma omp parallel for      // Linha seguinte DEVE ser um comando for\n",
        "  for (i=0; i < NUM; i++) {     // (*)\n",
        "    printf(\"Thread %d tratando iteração %d\\n\", omp_get_thread_num(), i);\n",
        "    vet[i] = 2 * i;  \n",
        "  }\n",
        "  ...\n",
        "```\n",
        "(\\*) É importante observar que, para que cada *thread* do time execute uma parte das iterações, cada uma deve ter sua própria cópia da variável de controle do *loop*. Isso significa que, neste caso, a variável ***i***, usada como índice do comando *for*, deve ser **privada**. O compilador com suporte a OpenMP, contudo, faz com que essa variável seja privada automaticamente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x5U5Do1pRP_"
      },
      "source": [
        "**Controlando a divisão das iterações**\n",
        "\n",
        "Uma vez entendido que as iterações de um comando for paralelo serão **divididas** entre as *threads* do time, podemos pensar em como essa divisão ocorrerá.\n",
        "\n",
        "Por padrão, a divisão é em bloco, de forma que cada *thread* será encarregada de 1 / N das iterações. Vale lembrar que cada *thread* num time tem um número lógico que vai de 0 (para a *thread master*) a N-1.\n",
        "\n",
        "Assim, a *thread* ***i*** vai executar as iterações  **i * (1/N) .. (i+1) * (1/N) -1**\n",
        "\n",
        "Por exemplo, com 12 iterações e 4 *threads*, a thread 0 vai executar as iterações 0, 1 e 2, a *thread* 1 vai executar as iterações 3, 4 e 5, a *thread* 2 vai executar 6, 7 e 8, e, por fim, a *thread* 3 vai executar as iterações 9, 10 e 11.\n",
        "\n",
        "O compilador está atento, contudo, e consegue tratar os **casos em que essa divisão não é exata**! Neste caso, comumente, as *threads* com identificador menor do que o \"resto da divisão inteira\" das iterações pelo número de *threads* recebem **uma iteração a mais cada uma**.\n",
        "\n",
        "A forma de divisão das iterações pode ser controlada pelo programador, por exemplo, usando a cláusula *schedule* na primitiva for.\n",
        "\n",
        "De acordo com as especificações, o comportamento da divisão de iterações pode variar como segue:\n",
        "\n",
        "* *STATIC: Loop iterations are divided into pieces of size chunk and then statically assigned to threads. If chunk is not specified, the iterations are evenly (if possible) divided contiguously among the threads.*\n",
        "* *DYNAMIC: Loop iterations are divided into pieces of size chunk, and dynamically scheduled among the threads; when a thread finishes one chunk, it is dynamically assigned another. The default chunk size is 1.*\n",
        "* *GUIDED: For a chunk size of 1, the size of each chunk is proportional to the number of unassigned iterations divided by the number of threads, decreasing to 1. For a chunk size with value k (greater than 1), the size of each chunk is determined in the same way with the restriction that the chunks do not contain fewer than k iterations (except for the last chunk to be assigned, which may have fewer than k iterations). The default chunk size is 1.*\n",
        "* *RUNTIME: The scheduling decision is deferred until runtime by the environment variable OMP_SCHEDULE. It is illegal to specify a chunk size for this clause.*\n",
        "* *AUTO: The scheduling decision is delegated to the compiler and/or runtime system.*\n",
        "\n",
        "A definição da política de escalonamento das iterações pode ocorrer de três formas:\n",
        "* via **cláusula schedule** na diretiva *for*,\n",
        "* via chamada à função ***omp_set_schedule(omp_sched_tkind, intchunk_size)*** e\n",
        "* via variável de ambiente **OMP_SCHEDULE**.\n",
        "\n",
        "Vejamos um programa que realiza a divisão das iterações via primitiva *for* numa região paralela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvN3s533pgq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89613999-bc50-4148-f2e3-94a412861de4"
      },
      "source": [
        "%%writefile pfor.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>\n",
        "\n",
        "#define NUM 12\n",
        "\n",
        "int\n",
        "main(int argc, char **argv)\n",
        "{\n",
        "  int i, ind, vet[NUM];\n",
        "\n",
        " #pragma omp parallel private(ind)\n",
        " {\n",
        "   ind = omp_get_thread_num();\n",
        "\n",
        "   #pragma omp for schedule(runtime)\n",
        "   for (i=0; i < NUM; i++) {\n",
        "     printf(\"Thread %d executando iteracao %d\\n\", ind, i);\n",
        "     vet[i] = 2 * i;\n",
        "   }\n",
        " }\n",
        "\n",
        " return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pfor.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_aPkqeXp1Sn"
      },
      "source": [
        "Vejamos o resultado da execução usando diferentes formas de particionamento das iterações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhXG4lxEpvs4"
      },
      "source": [
        "! gcc pfor.c -o pfor -fopenmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVBcCjO7qC7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0cb9c3-d86e-49b3-8503-91aae28e65f0"
      },
      "source": [
        "! OMP_SCHEDULE=static ./pfor | sort"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0 executando iteracao 0\n",
            "Thread 0 executando iteracao 1\n",
            "Thread 0 executando iteracao 2\n",
            "Thread 0 executando iteracao 3\n",
            "Thread 0 executando iteracao 4\n",
            "Thread 0 executando iteracao 5\n",
            "Thread 1 executando iteracao 10\n",
            "Thread 1 executando iteracao 11\n",
            "Thread 1 executando iteracao 6\n",
            "Thread 1 executando iteracao 7\n",
            "Thread 1 executando iteracao 8\n",
            "Thread 1 executando iteracao 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1A2vi8tqOn4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231d4bd0-4751-47c6-e124-ccc73fe2cb7b"
      },
      "source": [
        "! OMP_SCHEDULE=dynamic ./pfor | sort"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0 executando iteracao 1\n",
            "Thread 1 executando iteracao 0\n",
            "Thread 1 executando iteracao 10\n",
            "Thread 1 executando iteracao 11\n",
            "Thread 1 executando iteracao 2\n",
            "Thread 1 executando iteracao 3\n",
            "Thread 1 executando iteracao 4\n",
            "Thread 1 executando iteracao 5\n",
            "Thread 1 executando iteracao 6\n",
            "Thread 1 executando iteracao 7\n",
            "Thread 1 executando iteracao 8\n",
            "Thread 1 executando iteracao 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njm-vaEFqZcO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8871a1dd-176c-430d-fcad-d8fb359d9b4a"
      },
      "source": [
        "! OMP_NUM_THREADS=4 OMP_SCHEDULE=guided ./pfor | sort"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 0 executando iteracao 0\n",
            "Thread 0 executando iteracao 1\n",
            "Thread 0 executando iteracao 10\n",
            "Thread 0 executando iteracao 11\n",
            "Thread 0 executando iteracao 2\n",
            "Thread 0 executando iteracao 6\n",
            "Thread 0 executando iteracao 7\n",
            "Thread 0 executando iteracao 8\n",
            "Thread 0 executando iteracao 9\n",
            "Thread 1 executando iteracao 3\n",
            "Thread 1 executando iteracao 4\n",
            "Thread 1 executando iteracao 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDbyeUl5pxQw"
      },
      "source": [
        "**Resumindo?**\n",
        "\n",
        "Se o trecho com maior processamento no seu programa é um ***loop for***, cujas iterações podem ser executadas em paralelo, a paralelização deste código com OpenMP pode ser feita em uma linha!\n",
        "\n",
        "Além disso, a forma de divisão das iterações pode ser ajustada cada vez que você for executar o programa!\n",
        "\n",
        "Ou seja, para experimentar com diferentes formas de divisão das iterações e com diferentes números de *threads*, nem é preciso recompilar o programa!\n",
        "\n",
        "```\n",
        "  ...\n",
        "  #pragma omp parallel for\n",
        "  for( ...; ...; ...) {\n",
        "    ...\n",
        "  }\n",
        "  ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que tal pensarmos no impacto do algoritmo de atribuição das iterações?\n",
        "\n",
        "Afinal, por que fazer a atribuição de outra forma que não em blocos (N_it / num_threads) ?"
      ],
      "metadata": {
        "id": "NOugoJjX73v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile para-for.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <unistd.h>\n",
        "\n",
        "#define N 1000\n",
        "\n",
        "int\n",
        "main()\n",
        "{\n",
        "  int i;\n",
        "\n",
        "  #pragma omp parallel for\n",
        "  for (i=0; i< N; i++)\n",
        "    // simula algum processamento que depende do índice da iteração sendo calculada\n",
        "    // quanto maior a iteração, mais processamento.\n",
        "    // Se divisão for estática, thread que ficar com o último bloco de iterações terá mais trabalho\n",
        "    // usleep( i * 40 );\n",
        "    for (int j=0; j< 1000 * i * 30; j++);\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yGdgOCx7Ppb",
        "outputId": "2de2736f-a277-47eb-cdaf-abe5728363a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing para-for.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if $( ! apt list time 2>&1 | grep \"installed\" ) ; then apt install time &> /dev/null; fi\n",
        "! if [ ! para-for -nt para-for.c ]; then gcc -Wall para-for.c -o para-for -fopenmp; fi\n",
        "\n",
        "! echo static:\n",
        "! OMP_SCHEDULE=static time -p ./para-for\n",
        "! echo; echo dynamic:\n",
        "! OMP_SCHEDULE=dynamic time -p ./para-for\n",
        "! echo; echo guided:\n",
        "! OMP_SCHEDULE=guided time -p ./para-for\n",
        "# ! echo; echo guided, chunk=2:\n",
        "# ! export OMP_SCHEDULE=\"guided,10\"\n",
        "# ! OMP_SCHEDULE=\"guided,2\" time -p ./para-for\n",
        "# ! echo; echo guided, chunk=10:\n",
        "# ! OMP_SCHEDULE=\"guided,10\" time -p ./para-for"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP02YOn58tzZ",
        "outputId": "30e5e535-be48-498c-b42e-6315f69a37ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "static:\n",
            "real 25.88\n",
            "user 31.98\n",
            "sys 0.01\n",
            "\n",
            "dynamic:\n",
            "real 25.46\n",
            "user 32.09\n",
            "sys 0.02\n",
            "\n",
            "guided:\n",
            "real 24.36\n",
            "user 32.41\n",
            "sys 0.00\n"
          ]
        }
      ]
    }
  ]
}