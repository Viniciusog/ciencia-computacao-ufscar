{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EZFTgQcHIAc"
      },
      "source": [
        "# PPD: OpenMP\n",
        "\n",
        "Hélio - DC/UFSCar - 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP2UF_h7R0-I"
      },
      "source": [
        "# Programação paralela com extensões de linguagem: OpenMP\n",
        "\n",
        "Há algum tempo, o aumento de desempenho dos sistemas computacionais passou a ser buscado a partir da replicação de suas unidades funcionais, já que estava cada vez mais difícil simplesmente aumentar a velocidade dos processadores.\n",
        "\n",
        "Processadores com vários núcleos (*cores*) e múltiplos processadores passaram a ser utilizados em computadores servidores e até em computadores pessoais e smartphones!\n",
        "\n",
        "Como resultado, programadores que buscam aumentar o desempenho de suas aplicações passaram a ter que paralelizar os códigos utilizados. Visto pela complexidade da [programação com a biblioteca de *pthreads*](https://computing.llnl.gov/tutorials/pthreads/), contudo, essa não é uma tarefa fácil.\n",
        "\n",
        "Por outro lado, também não é simples para um compilador detectar automaticamente quais atividades de um programa podem ser executadas em paralelo e ajustar o código para isso. Questões relacionadas a dependências de dados tanto podem fazer com que um programa tenha trechos paralelizados de maneira indevida, quanto que sejam mantidos sequenciais em situações em que o compilador não tem certeza da ausência de erros com a  paralelização.\n",
        "\n",
        "Assim, uma estratégia intermediária foi considerada para a **transformação de código sequencial** existente **em código paralelo**: **usar dicas do programador**, na forma de marcas (**pragmas**) adicionadas ao código, e paralelização dos cógigos indicados, usando *threads*, feita pelo compilador.\n",
        "\n",
        "**OpenMP** (*Open Multi-Processing* - http://openmp.org) é uma interface de programação (API) que possibilita o desenvolvimento de programas em C/C++ e Fortran para ambientes multiprocessados.\n",
        "\n",
        "Definido por um grupo formado por grandes fabricantes de hardware e software, OpenMP é um modelo portável e escalável que provê uma interface simples e flexível para o desenvolvimento de aplicações paralelas para execução em computadores com memória compartilhada.\n",
        "\n",
        "Diferentes arquiteturas são suportadas, variando de estações de trabalho a supercomputadores, incluindo plataformas Unix e Windows.\n",
        "\n",
        "De maneira geral, OpenMP consiste em um conjunto de diretivas de compilação, em uma biblioteca de funções e em variáveis de ambiente que influenciam o comportamento da execução de programas.\n",
        "\n",
        "# Modelo de programação\n",
        "\n",
        "Originalmente, o modelo de programação oferecido por OpenMP é o de paralelismo baseado em *threads* para ambiente com memória compartilhada (*Shared Memory, Thread Based Paralelism*). Assim, o cenário típico para uso desse mecanismo são os computadores ***multicores***.\n",
        "\n",
        "    Versões mais recentes das especificações OPenMP também têm suporte para paralelismo\n",
        "    usando aceleradores e GPGPUs mas, por ora, trataremos de CPUs.\n",
        "\n",
        "OpenMP permite:\n",
        "\n",
        "* Criar times de *threads* para execução paralela de blocos de código\n",
        "* Especificar como dividir (*share*) as atividades de um bloco de código entre os membros de um grupo\n",
        "* Declarar variáveis compartilhadas e privadas\n",
        "* Sincronizar *threads* e permitir que executem operações de maneira exclusiva\n",
        "* Executar *loops* usando operações SIMD\n",
        "* Utilizar dispositivos como GPUs para processamento vetorial\n",
        "\n",
        "OpenMP suporta ambos os modelos de [decomposição](https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial#Designing) das atividades: decomposição de código (funcional) e decomposição dados (de domínio).\n",
        "\n",
        "* Paralelismo das atividade com OpenMP é definido de maneira explícita, não automática, com controle total do programador.\n",
        "* Paralelismo é especificado por diretivas de compilação (pragmas em C/C++ (*pragmatic information*)), que permitem passar informações ao compilador.\n",
        "* Informações passadas pelos *pragmas* podem ser ignoradas pelo compilador sem alterar a correção do código gerado.\n",
        "* Esforço de paralelização de um programa com OpenMP resume-se, em geral, à identificação do paralelismo e não à reprogramação do código para implementar o paralelismo desejado.\n",
        "\n",
        "Diferentes compiladores têm suporte à programacão com OpenMP: [compilers and tools](https://www.openmp.org/resources/openmp-compilers-tools/).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compilando programas OpenMP com gcc\n",
        "\n",
        "Como OpenMP trata de extensões de linguagem, o suporte ao seu uso também deve ser oferecido diretamente **pelo compilador** utilizado. Assim, não basta apenas incluir definições e ligar bibliotecas ao código, mas é preciso saber quais parâmetros são necessários pelo compilador em uso.\n",
        "\n",
        "Diferentes implementações de compiladores C/C++ e Fortran têm suporte a OpenMP, o que inclui [gcc](https://gcc.gnu.org/wiki/openmp).\n",
        "\n",
        "Para compilar e gerar código executável C com OpenMP em gcc:\n",
        "```\n",
        "$ gcc prog.c -o prog -fopenmp  ...         // compila programa, incluindo suporte para openmp\n",
        "````\n",
        "Para saber mais, vale ler o manual:\n",
        "```\n",
        "$ man gcc                // sempre bom consultar o manual :-)\n",
        "\n",
        "  /openmp                // busca por openmp ...\n",
        "\n",
        "-fopenmp\n",
        "  Enable handling of OpenMP directives \"#pragma omp\" in C/C++ ...\n",
        "  When -fopenmp is specified, the compiler generates parallel code according\n",
        "  to the  OpenMP Application Program Interface v2.5 <http://www.openmp.org/>.\n",
        "  This option implies -pthread, and thus is only supported on targets that\n",
        "  have support for -pthread.\n",
        "```"
      ],
      "metadata": {
        "id": "vQzJLAdI7f-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vale saber também que as especificações OpenMP foram evoluindo ao longo do tempo e incluindo novas funcionaliddes. Assim, pode ser relevante saber qual é a versão OpenMP suportada pelo compilador.\n",
        "\n",
        "\n",
        "https://www.openmp.org/specifications/\n",
        "\n",
        "    OpenMP 5.2 Specification – Nov 2021\n",
        "    OpenMP 5.1 Specification – Nov 2020\n",
        "    OpenMP 5.0 Specification – Nov 2018\n",
        "    OpenMP 4.5 Specification – Nov 2015\n",
        "    OpenMP 4.0 Specification – Jul 2013\n",
        "    OpenMP 3.1 Specification – Jul 2011\n",
        "\n",
        "\n",
        "Usando o compilador *gcc*, por exemplo, pode-se saber a verão OpenMP suportada consultando-se um valor pré-definido pela biblioteca *incluída* no programa:\n",
        "\n",
        "    The _OPENMP macro is defined by OpenMP-compliante implementations as the decimal constant\n",
        "    yyyymm, which will be the year and month of the approved specification."
      ],
      "metadata": {
        "id": "HJswX65bZnOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile version.c\n",
        "\n",
        "#include <omp.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int\n",
        "main()\n",
        "{\n",
        "  /*\n",
        "    https://www.openmp.org/specifications/\n",
        "\n",
        "    The _OPENMP macro is defined by OpenMP-compliante implementations as the decimal constant\n",
        "    yyyymm, which will be the year and month of the approved specification.\n",
        "\n",
        "    OpenMP 5.2 Specification – Nov 2021\n",
        "    OpenMP 5.1 Specification – Nov 2020\n",
        "    OpenMP 5.0 Specification – Nov 2018\n",
        "    OpenMP 4.5 Specification – Nov 2015\n",
        "    OpenMP 4.0 Specification – Jul 2013\n",
        "    OpenMP 3.1 Specification – Jul 2011\n",
        "  */\n",
        "\n",
        "#ifdef _OPENMP\n",
        "  printf(\"Compiled by an OpenMP-compliant implementation: %d\\n\",_OPENMP);\n",
        "#endif\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Zq_ZUfZrr2",
        "outputId": "9ee1671e-96d6-4d63-be36-731a621e6b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing version.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! if [ ! version -nt version.c ]; then gcc version.c -o version -fopenmp; fi\n",
        "! ./version\n",
        "# ! clang version.c -o clang-ver -fopenmp -stdlib=libc++ -Xopenmp && ./clang-ver"
      ],
      "metadata": {
        "id": "utiyYh5ZZ6lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e50654-2ad1-45e5-f943-8664bf4656f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled by an OpenMP-compliant implementation: 201511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIawix79ekOe"
      },
      "source": [
        "# Paralelismo com OpenMP\n",
        "\n",
        "De maneira geral, a paralelização de códigos com OpenMP é feita da seuinte forma:\n",
        "\n",
        "* programador insere diretivas (**#pragmas**) no código, indicando ao compilador qual linha ou bloco de código devem ser paralelizados e de qual forma;\n",
        "* compilador identifica as diretivas e transforma o código sequencial em um código paralelo.\n",
        "\n",
        "Diretivas (pragmas) são inseridas como linhas de código e aplicam-se à linha de código logo abaixo. Quando o objetivo é aplicar uma diretiva a um bloco de código, com várias linhas, é preciso envolver este bloco de código com o uso de chaves \"{ ... }\".\n",
        "\n",
        "As diretivas OpenMP especificadas como *pragmas* têm a seguinte sintaxe:\n",
        "\n",
        "```\n",
        "#pragma omp nome_da_diretiva [ cláusulas_da_diretiva ]\n",
        "```\n",
        "\n",
        "Como se observa, primitivas podem, opcionalmente, ter **cláusulas** variadas, que definem aspectos do funcionamento da diretiva.\n",
        "\n",
        "Caso o compilador utilizado não tenha suporte a OpenMP, ou se o parâmetro ***-fopenmp*** não for especificado na invocação do compilador ***gcc***, por exemplo, as linhas contendo as diretivas (#pragmas) serão simplesmente ignoradas na compilação.\n",
        "\n",
        "<br>\n",
        "\n",
        "Os exemplos a seguir mostram a paralelização de um bloco de código usando a diretiva ***parallel***, especificada como uma *pragma* no código.\n",
        "\n",
        "\n",
        "No exemplo abaixo, vemos o uso da diretiva *parallel* para criar **um time de *threads***. As diretivas sempre se aplicam à linha de código imediatamente abaixo, ou ao bloco de código definido entre chaves \\{ ... \\} . Neste caso, tudo que está dentro do bloco de código definido a partir da linha seguinte à *pragma*, será executado por todas as *threads* do time.\n",
        "\n",
        "Nesse caso, vê-se também que a **diretiva *parallel*** tem uma cláusula, **num_threads(4)**, que especifica quantas *threads* deverão ser usadas para a execução paralela do bloco a seguir.\n",
        "\n",
        "Apenas uma *thread*, aquela que encontrou a construção paralela e criou o time de *threads*, prossegue em execução após a região paralela. Neste caso, era a *thread* associada à função *main*. Apenas essa *thread* prossegue em execução, de forma que o comando *printf* final neste caso só será executado uma vez.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjGR6mIMgtuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3db460-d753-435d-acad-1ba81518522b"
      },
      "source": [
        "%%writefile p1.c\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "int main ()\n",
        "{\n",
        "  // ...   // Código serial, executado por apenas 1 thread, como usual\n",
        "  // ...\n",
        "\n",
        "  // Uso da diretiva parallel para criar uma região paralela:\n",
        "  #pragma omp parallel num_threads(4)\n",
        "  {\n",
        "    // Seção paralela, executada por todas as threads do time\n",
        "    printf(\"Hello, world!\\n\");\n",
        "  }\n",
        "  // Ao fim do bloco de código da região paralela, a thread master espera pela conclusão das demais\n",
        "  // Apenas thread master (aquela que encontrou a região paralela e criou o time) prossegue execução\n",
        "\n",
        "  printf(\"Goodbye\\n\");\n",
        "  // ...\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting p1.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mvC_pCofB1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0c6ec8-1a4f-465b-f1f6-03de33d60952"
      },
      "source": [
        "! gcc p1.c -o p1 -fopenmp && ./p1\n",
        "! echo\n",
        "# Observe que se o código for compilado sem o parâmetro \"-fopenmp\" as linhas com pragmas serão ignoradas e não haverá paralelismo\n",
        "! gcc p1.c -o p1 && ./p1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, world!\n",
            "Hello, world!\n",
            "Hello, world!\n",
            "Hello, world!\n",
            "Goodbye\n",
            "\n",
            "Hello, world!\n",
            "Goodbye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sUaifQOfc6G"
      },
      "source": [
        "Neste segundo exemplo, repete-se a criação de um time de *threads* para execução paralela de um bloco de código. É importante observar que, como não foram especificadas quantas *threads* usar, o compilador tomará como base um valor *default*, que é igual ao número de núcleos de processamento (cores) existentes no sistema. O controle sobre o número de *threads* será tratado com mais detalhes em um bloco posterior.\n",
        "\n",
        "Outro aspecto a observar é o uso de 2 chamadas da **API omp**. Para usá-las, é preciso incluir o arquivo de cabeçalhos ***omp.h*** no código.\n",
        "\n",
        "A função ***omp_get_thread_num***() retorna o número lógico de cada *thread* dentro do time que está executando a região paralela.\n",
        "\n",
        "Já a função ***omp_get_num_threads***() indica quantas *threads* há no time atual. O conhecimento desses índices pode ser útil quando o programador deseja controlar explicitamente o que cada *thread* do time irá fazer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsT7LCJgegX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928c0e40-feaa-465d-c531-f02a1ca5c614"
      },
      "source": [
        "%%writefile p2.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <omp.h>   // necessário apenas se formos usar funções da API omp\n",
        "#include <sched.h> // p/ sched_getcpu\n",
        "\n",
        "// ...\n",
        "\n",
        "int main ()\n",
        "{\n",
        "  // ...\n",
        "  // Início de seção paralela: geração das threads do time\n",
        "  #pragma omp parallel\n",
        "  {\n",
        "    // ...\n",
        "    // Seção parcláusulaalela, executada por todas as threads do time\n",
        "    printf(\"Esta é a thread %d de um time de %d.\\n\",\n",
        "            omp_get_thread_num(), omp_get_num_threads() );\n",
        "    // ...\n",
        "  }\n",
        "  // Apenas master thread prossegue execução após o bloco paralelo\n",
        "  // ...\n",
        "  printf(\"Terminando...\\n\");\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing p2.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuGs_69FfjNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fec454b4-cfee-44a2-d208-6a9d5268ca3b"
      },
      "source": [
        "! gcc -Wall p2.c -o p2 -fopenmp && ./p2\n",
        "! OMP_NUM_THREADS=4 ./p2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esta é a thread 1 de um time de 2.\n",
            "Esta é a thread 0 de um time de 2.\n",
            "Terminando...\n",
            "Esta é a thread 0 de um time de 4.\n",
            "Esta é a thread 2 de um time de 4.\n",
            "Esta é a thread 1 de um time de 4.\n",
            "Esta é a thread 3 de um time de 4.\n",
            "Terminando...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqxss_bigJ02"
      },
      "source": [
        "# Tratamento de variáveis\n",
        "\n",
        "Um aspecto importante na programação com *threads* é tratamento das variávies do programa. Como *threads* compartilham as áreas de memória do processo ao qual estão associadas, é preciso atenção para qual será o efeito da criação automática de várias *threads* no programa com relação às variáveis utilizadas.\n",
        "\n",
        "No exemplo a seguir, ilustra-se a definição de escopo de variáveis dentro de um bloco paralelo. Por padrão, qualquer **variável global**, ou qualquer variável definida dentro da função *main* neste caso, que é acessível dentro do código da região paralela, será **compartilhada** por todas as *threads* do time. Isso significa que qualquer modificação de uma dessas variáveis ocorrerá sobre a única instância, compartilhada por todas as *threads* do processo.\n",
        "\n",
        "Na criação de um time de *threads* com a diretiva ***parallel***, contudo, há cláusulas específicas que podem ser usadas para **definir o escopo** de variáveis:\n",
        "\n",
        "* a cláusula ***private***() indica uma lista de variáveis que serão **privadas**, ou seja, cada *thread* terá uma cópia dessas variáveis;\n",
        "* já a cláusula ***shared***() indica que as variáveis listadas serão **compartilhadas** pelas *threads* do time.\n",
        "\n",
        "Por padrão, variáveis **não mencionadas nas cláusulas** de uma diretiva são tratadas como **compartilhadas**. Assim, todas as referências a uma variável vão se referir à mesma posição de memória. Caso esse não seja o comportamento desejado, é preciso especificar esta variável na lista de variáveis privadas.\n",
        "\n",
        "Variáveis que forem **definidas dentro do bloco paralelo** (o que é permitido se não for usada a sintaxe C ansi ou -std=c90) também **serão privadas** para cada *thread*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN5cdHnoesvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a15298-1c8f-47c4-91d8-6e5f72258851"
      },
      "source": [
        "%%writefile p3.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>  // para funcao rand()\n",
        "#include <time.h>    // para funcao time()\n",
        "#include <omp.h>     // necessário apenas se formos usar funções da API omp\n",
        "\n",
        "int main ()\n",
        "{\n",
        "  int var1, var2;\n",
        "  // ...\n",
        "  srand(time(NULL));\n",
        "\n",
        "  var2 = 0;\n",
        "\n",
        "  // Região paralela com definição do escopo de variáveis usadas no trecho paralelo.\n",
        "  #pragma omp parallel private(var1) shared(var2)\n",
        "  {\n",
        "    int ind;      // variáveis definidas dentro da região paralela são privadas para cada thread do time\n",
        "\n",
        "    ind = omp_get_thread_num();   // obtem numero logico da thread e salva em índice local\n",
        "\n",
        "    // ...\n",
        "    var1 = rand(); // como var1 é privada, cada thread terá uma instância de variável com esse nome\n",
        "    // ...\n",
        "\n",
        "    // var2 =      // será que todas as threads podem atualizar essa variavel ao mesmo tempo?\n",
        "cláusula\n",
        "    printf(\"Thread %d: var1 = %d\\n\", ind, var1);\n",
        "\n",
        "    // ...\n",
        "  }\n",
        "\n",
        "  // Apenas master thread prossegue execução após o bloco paralelo\n",
        "  printf(\"\\nFim\\n\");\n",
        "\n",
        "  // ...\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing p3.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azxi39IEgN9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e146d51-3aa4-45e7-c653-0020ed7457de"
      },
      "source": [
        "! gcc p3.c -o p3 -fopenmp && ./p3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thread 1: var1 = 402086149\n",
            "Thread 0: var1 = 948431464\n",
            "\n",
            "Fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_M_bBjeZ5va"
      },
      "source": [
        "# Definindo o número de *threas* numa região paralela\n",
        "\n",
        "O número de *threads* numa região paralela é determinado por diversos fatores:\n",
        "\n",
        "* Avaliação da cláusula IF (se presente na diretiva)\n",
        "* Ajuste da cláusula ***num_threads*** na diretiva\n",
        "* Uso da função ***omp_set_num_threads()*** antes da diretiva parallel\n",
        "* Ajuste da variável de ambiente **OMP_NUM_THREADS** antes de iniciar a execução do programa\n",
        "* Número de processadores (e *cores*) disponíveis\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeDKT0M-Z-gn",
        "outputId": "13275001-d0d5-4b67-f85e-cbe7bcba60a5"
      },
      "source": [
        "%%writefile p4.c\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>   // para rand()\n",
        "#include <time.h>     // para time()\n",
        "#include <omp.h>      // para funções OpenMP\n",
        "\n",
        "int\n",
        "main()\n",
        "{\n",
        "  int impar;\n",
        "\n",
        "  #pragma omp parallel\n",
        "  printf(\"Thread %d de %d\\n\",omp_get_thread_num(), omp_get_num_threads());\n",
        "\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  #pragma omp parallel num_threads(4)\n",
        "  printf(\"Thread %d de %d\\n\",omp_get_thread_num(), omp_get_num_threads());\n",
        "\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  omp_set_num_threads(6);\n",
        "\n",
        "  #pragma omp parallel\n",
        "  printf(\"Thread %d de %d\\n\",omp_get_thread_num(), omp_getpor_num_threads());\n",
        "\n",
        "  printf(\"\\n\");\n",
        "\n",
        "  srand(time(NULL));\n",
        "  impar = rand()%2;\n",
        "\n",
        "  #pragma omp parallel if(impar)\n",
        "  printf(\"Thread %d de %d\\n\",omp_get_thread_num(), omp_get_num_threads());\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting p4.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l7grDJ_jXLw"
      },
      "source": [
        "! gcc -Wall p4.c -o p4 -fopenmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIU_UIjAbsS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362b4743-ccc4-4818-bf3c-11cfc918f900"
      },
      "source": [
        "! lscpu | grep \"CPU(s)\" && \\\n",
        " echo && echo \"Executando sem ajustar OMP_NUM_THREADS\" && echo \"\" && \\\n",
        " ./p4 && \\\n",
        " echo \"\" && echo \"Executando com OMP_NUM_THREADS=3\" && echo \"\" && \\\n",
        " OMP_NUM_THREADS=3 ./p4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU(s):                          2\n",
            "On-line CPU(s) list:             0,1\n",
            "NUMA node0 CPU(s):               0,1\n",
            "\n",
            "Executando sem ajustar OMP_NUM_THREADS\n",
            "\n",
            "Thread 1 de 2\n",
            "Thread 0 de 2\n",
            "\n",
            "Thread 1 de 4\n",
            "Thread 0 de 4\n",
            "Thread 3 de 4\n",
            "Thread 2 de 4\n",
            "\n",
            "Thread 1 de 6\n",
            "Thread 3 de 6\n",
            "Thread 2 de 6\n",
            "Thread 0 de 6\n",
            "Thread 4 de 6\n",
            "Thread 5 de 6\n",
            "\n",
            "Thread 0 de 1\n",
            "\n",
            "Executando com OMP_NUM_THREADS=3\n",
            "\n",
            "Thread 0 de 3\n",
            "Thread 2 de 3\n",
            "Thread 1 de 3\n",
            "\n",
            "Thread 3 de 4\n",
            "Thread 0 de 4\n",
            "Thread 1 de 4\n",
            "Thread 2 de 4\n",
            "\n",
            "Thread 3 de 6\n",
            "Thread 4 de 6\n",
            "Thread 0 de 6\n",
            "Thread 5 de 6\n",
            "Thread 2 de 6\n",
            "Thread 1 de 6\n",
            "\n",
            "Thread 0 de 1\n"
          ]
        }
      ]
    }
  ]
}